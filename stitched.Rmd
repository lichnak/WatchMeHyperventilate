---
output:
  word_document:
    fig_caption: true
  pdf_document:
    fig_caption: true
    latex_engine: xelatex
    keep_tex: yes
header-includes:
   - \usepackage{booktabs}
   - \usepackage[font={small},labelfont=bf,labelsep=colon]{caption}
   - \linespread{1.5}
   - \usepackage[compact]{titlesec}
   - \usepackage{enumitem}
   - \usepackage{tikz}
   - \def\checkmark{\tikz\fill[scale=0.4](0,.35) -- (.25,0) -- (1,.7) -- (.25,.15) -- cycle;}
   - \setlist{nolistsep}
   - \titlespacing{\section}{2pt}{*0}{*0}
   - \titlespacing{\subsection}{2pt}{*0}{*0}
   - \titlespacing{\subsubsection}{2pt}{*0}{*0}
   - \setlength{\parskip}{3pt}
bibliography: references.bib
csl: national-science-foundation-grant-proposals.csl
fontsize: 11pt
mainfont: Georgia
geometry: margin=1.0in
---

<!--
   - \setlength{\parskip}{3pt}
   - \setlength{\topsep}{0pt}
   - \setlength{\partopsep}{0pt}
   - \setlength{\itemsep}{0pt}
   - \setlength{\floatsep}{0pt}
   - \setlength{\intextsep}{2pt}
   - \setlength{\abovecaptionskip}{2pt}
   - \setlength{\belowcaptionskip}{0pt}
-->


<style type="text/css">
body,
code.bash{
  font-size: 8px;
}
pre {
  font-size: 8px
}
</style>



```{r setup, include=FALSE}
knitr::opts_chunk$set( cache=TRUE )
```

\pagenumbering{gobble}

# Introduction

## White matter hyperintensities in TBI

White matter hyperintensities (WMHs) are foci of abnormally increased signal intensity seen within white matter regions within the cerebrum and brainstem on fluid attenuation inversion recovery (FLAIR) magnetic resonance imaging (MRI) sequences. These lesions are distinguished from prominent perivascular spaces seen on T2-weighted imaging by the lack of fluid suppression of signal on FLAIR sequences. WMHs in the periventricular and deep brain regions are associated with normal aging and neurological conditions including hypertension and stroke. WMHs are also a frequent finding following traumatic brain injury (TBI) and have been correlated with functional outcome and injury severity in both pediatric [@Bigler:2013aa;@Smitherman:2016aa] and adult
[@Marquez-de-la-Plata:2007aa;@Moen:2014aa;@Ding:2008aa;@Pierallini:2000aa]. Further, the regional distribution and volume of WMHs have been shown to possess prognostic value in the TBI patient [@Pierallini:2000aa;@Weiss:2008aa;@Smitherman:2016aa;@Levin:1988aa]. Specifically, lesion volume in corpus callosum correlates with functional scores in the acute phase following injury, while lesion volume in frontal lobes correlates with scores at 1 year following injury [@Pierallini:2000aa]. Further, volume of FLAIR lesions within the corpus callosum, brainstem, and thalamus in patients with severe TBI correlates with Glasgow Outcome-Extended (GOS-E) scores [@Moen:2014aa]. Additionally, the regional distribution of FLAIR lesions within the pons, midbrain, hypothalamus, basal forebrain, parietal, temporal, occipital lobes, and insula along with the observation of grasping or chewing behavior are associated with poor outcome [@Weiss:2008aa].

Despite the above findings, outside of multiple sclerosis, WMHs are not routinely employed as a diagnostic measure in clinical practice. Their presence within asymptomatic patients or in association with a variety of conditions, such as stroke, dementia, neuroinflammatory conditions, and TBI challenge their utility in narrowing a radiological differential diagnosis. Further, performing a comprehensive manual counting of number and distribution of lesions in the clinical setting is simply not practical. Despite the limited inclusion of WMH observations in routine radiological reports, two large meta-analyses demonstrated an association between WMHs, cognitive function, increased risk of stroke, dementia, and death [@Debette:2010aa;@Kloppenborg:2014aa]. As such, the development of automated methods for the rapid identification and quantification of WMHs within individual patients may allow for identification of correlative patterns between WMH number, volume, distribution, and disease state. Further, the development of such lesion quantification approaches may allow for the practical inclusion of this type of information within routine radiological practice.

## Random forests for WMH segmentation


Machine learning and pattern recognition techniques have seen increased application
for various medical image analysis workflows (see, for example, the annual
Workshop on Machine Learning in Medical Imaging held in conjunction with the Medical
Image Computing and Computer-Aided Intervention (MICCAI) international meeting [@mlmi2015]).
Popular techniques such as support vector machines and neural networks have been applied
successfully to clinically relevant imaging tasks such as supervised image segmentation
(e.g., [@Bauer:2011aa]) and diagnostic prediction (e.g., [@Tong:2014aa;@Liu:2013aa]).
Facilitating the current employment of such techniques are the number of available imaging
data sets [@Van-Horn:2014aa] and the public availability of data science packages such as
SciPy [@scipy] and the R project for statistical computing [@R] and their associated
extensions.

The random forests framework [@breiman2001] is a popular machine learning technique that has
demonstrated significant utitility for supervised segmentation tasks (e.g.,
normal human brain segmentation [@yi2009]) and other computer vision applications
(e.g., human gait detection [@viola2005]).
In the context of neuropathology, random forest-based paradigms have been employed in the
delineation of multiple sclerosis lesions [@geremia2011], stroke lesions [@Pustina:2016aa],
and brain tumors [@geremia2012;@bauer2012;@zikic2012;@Tustison:2015aa].  Of note, these
latter random forest approaches for brain tumor segmentation have performed well in recent
international competitions.  In response to the lack of objective comparisons between
segmentation algorithms, the Multimodal Brain Tumor Segmentation (BRATS) challenge was initiated in
2012 [@Menze:2015aa] and has continued every year since under the auspices of the MICCAI
conference.

Random forests are conceptually simple [@breiman2001].  They consist of ensembles of decision trees
that are built from training data.  Once constructed, data to be classified is "pushed"
through each decision tree resulting in a single classification "vote" per tree.  These
votes are then used for regression or classification of the data.  Although decision
trees had been extensively studied previously, the success of employing collections of
such weak learners for boosting machine learning performance
(e.g., AdaBoost [@schapire1990;@freund1997]) influenced the similarly sytled conglomeration
of decision trees into "forests" with randomized node optimization [@ho1995;@amit1997].
Finally, Breiman [@breiman2001] improved accuracy by random sampling of the training
data (i.e., "bagging") resulting in the current random forest technique.

In this work, we develop a concatenated random forest framework with a tailored contextual
feature image set (both spatial and intensity-based)
for segmenting white matter hyperintensities in traumatic brain injury cohorts.  Additionally,
the entire framework is provided publicly through the well-known open-source
ANTs[^i1] and ANTsR[^i2] toolkits.  Further motivating the research of this work is
the public availability of the imaging data thus permitting full reproducibility
of the results reported and discussed.

[^i1]: https://github.com/stnava/ANTs
[^i2]: https://github.com/stnava/ANTsR

# Materials and Methods

## Imaging

## Quantitative analysis

<!--

* Importance of machine learning in medical image analysis
    x give examples
    x (tools) support vector machines
    x (tools) neural networks
    x (apps)
    x Random forests algorithms
        x MS lesion detection (Geremeria 2011)
        x Brain tumor segmentation (BRATS 2012 and BRATS 2013)
        x Tustison 2015 (importance of feature images)
        x Pustina 2016
    x Random forests overview

* Overview of protocol
    * Preprocess all images
        * Denoise
        * N4 bias correction
    * Create Stage 1 feature images
    * Use those as input to the first stage RF model to get RF voting maps
        * CSF
        * GM
        * WM
        * Deep GM
        * Brain stem
        * Cerebellum
        * WMHs
    * Use RF voting maps as priors for antsAtroposN4.sh to perform Bayesian-based
      segmentation with an additional Markov random field prior to promote spatial
      smoothness of the labels.
    * Use Stage 1 feature images + RF voting maps + antsAtroposN4.sh posteriors as
      Stage 2 feature images.
    * Remove isolated voxels as final refinement.


* Creation of feature images (all contained within ANTs)
    * Benefits of open source
    * best registration (for template building)
    * Preprocessing
        * Denoising
        * N4 bias correction
    * Types of feature images and motivation for their use (Stage 1)
        * Normalized intensities and neighborhood statistics image
        * Symmetric template --- the brain exhibits a shape and intensity bilateral
          symmetry under normal conditions.  WMHs can "break" this symmetry.
        * Probabilistic segmentations, distance maps and symmetric template indices ---
          help remove false positives
          caused by partial voluming at the gray/white matter interface and the location
          indices since, for example, higher intensities can be found at the periventricular
          caps in normal subjects [@Neema:2009aa] which often confounds automated lesion
          detection algorithms.
    * Types of feature images and motivation for their use (Stage 2)
        * All previously images (for the reasons stated above)
        * ``antsAtroposN4.sh`` with a large prior weight (w=0.5) on all three modalities
          to classify voxels based on intensity (use MRF to smooth out remaining noise
          in labeling).

* Public avail

* Leave one out evaluation strategy overview
    * Create stage 1 feature images for all subjects
    * For each of the 24 subjects, take out a subject and create a Stage 1 random forest
      model from the remaining feature images + manually labeled truth data.
    * For each of the remaining 23 subjects, send them through the Stage 1 RF model.
    * The above step permits the creation of the Stage 2 feature images
    * Create the Stage 2 RF model from the 23 sets of Stage 2 feature images.
    * Send the leave-one-out subject through the two RF models (as described above).
    * Compare with ground truth.

* (Save for Discusion) Difficulties of WMH evaluation (outlined in greater detail here [@MIAreview].
    *
-->


Crucial to these supervised segmentation approaches are the creation and selection of
"features" as input in conjunction with the ground-truth for model construction.  For the
targeted application in this work (i.e., WMHs),
regression/classification are performed at the voxelwise level.  In other words, each voxel
within the region of interest is sent through the ensemble of decision trees and receives
a set of classification votes from each tree thus permitting a regression or classification
solution.  Since this procedure is performed at the voxelwise level, intensity information
alone is insufficient for good segmentation performance due to the lack of spatial context.
For example, as pointed out in [@Neema:2009aa], higher intensities can be found at the
periventricular caps in normal subjects which often confounds automated lesion detection
algorithms.  Other potential confounds include MR signal inhomogeneity and noise.  Therefore,
even though machine learning and pattern recognition techniques are extremely powerful and
have significant potential, just as crucial to outcome is the creative construction and
deployment of salient feature images which we detail below.

### Feature images for WMH segmentation

\input{featureImagesTable.tex}

Supervised methodologies are uniquely characterized, in part, by the feature images that
are used to identify the regions of interest.  In Table 1, we provide a list and basic
categorization of the feature images used for the initial (i.e., Stage 1---more on the use
of multiple random forest stages below) segmentation of the white matter hyperintensities.
In addition Figure 1 provides a representation of a set of feature images for a single
subject analyzed in this work.  Note that in this work we categorize the brain parenchyma
with seven labels:

* cerebrospinal fluid (label 1),
* gray matter (label 2),
* white matter (label 3),
* deep gray matter (label 4),
* brain stem (label 5),
* cerebellum (label 6), and
* white matter hyperintensities (label 7).

![Representation of Stage 1 feature images for subject 01C1019.  The
FLAIR, T1-, and T2-weighted images are rigidly pre-aligned
[@Avants:2014aa] to the space of the T1 image.  The three modality images are then preprocessed
(N4 bias correction [@Tustison:2010ac] and adaptive denoising [@Manjon:2010aa]) followed by
application of standard ANTs brain extraction and $n$-tissue segmentation protocols using
the MMRR symmetric template and corresponding priors [@Tustison:2014ab] applied to the T1 image.
The feature images are then generated for voxelwise input to the RF model which results in
the voting maps illustrated on the right.  This gives a probabilistic classification of
tissue type.  Not shown are the probability and voting images for the brain stem and
cerebellum.](Figures/featureImages.png)

As mentioned previously, input for each subject comprises FLAIR, T1-, and T2-weighted
acquisitions.  The FLAIR and T2 images are rigidly registered to the T1 image using
the open-source Advanced Normalization Tools (ANTs) [@Avants:2014aa].  The aligned images
are then preprocessed using the denoising algorithm of [@Manjon:2010aa] followed by
N4 bias correction [@Tustison:2010ac] which are then normalized to the intensity
range $[0,1]$.  Although we could have used an alternative intensity standardization
algorithm (e.g., [@nyul2000]), we found that a simple linear rescaling produced better results.

![Sample FLAIR acquisition image slices showing both manual (top) and random forest
(RDF) segmentations (bottom) obtained during the leave-one-out evaluation.  Manual
segmentations were performed by one of the authors and provided the ground
truth WMH labels for training the random forest models.](Figures/montage.png)

The T1 image is then processed via the ANTs brain
extraction and normal tissue segmentation (i.e., the pathology is discounted which is
a fairly safe assumption for the T1 image) protocols described in [@Tustison:2014ab] in order to
produce a mask for the brain parenchyma and provide probabilistic estimates of the
cerebrospinal fluid (csf), gray matter, white matter, deep gray matter, brain stem, and
cerebellum.  These provide the ground-truth labels for the first six tissue labels
given above.  The white matter hyperintensities were manually identified by one of the authors
(J. R. S.) using the ITK-SNAP tool [@Yushkevich:2006aa].  Segmentation is performed using
the ANTs Atropos tool [@Avants:2011aa] and
multi-model optimal symmetric shape/intensity templates [@Tustison:2015aa] created from the public
MMRR data set  [@landman2011] (cf Figure 3).

![Canonical views of the mutlivariate, bilaterally symmetric template constructed
from the MMRR data set [@landman2011] (only shown are the FLAIR, T1, and T2 modalities---
the components relevant for this work).  Template construction is detailed in
[@Tustison:2015aa].  These images are important for specific intensity-based
features.](Figures/MMRR.png)

To model the intensity information the first set of images simply includes the
preprocessed and normalized intensity FLAIR, T1, and T2 image voxel values.  We also calculate a set
of neighborhood statistics (mean, standard deviation, and skewness) feature images using
a radius of one voxel. For each of the normalized
images, we calculate the difference in intensities with the corresponding warped template
component.  Previous success in the international brain tumor segmentation
competition [@Menze:2015aa] was based on an important set of intensity features that were created
from multi-modal templates mentioned previously [@Tustison:2015aa].  We employ the
same strategy here.  For example, the template
difference feature image for the FLAIR image, $S_{FLAIR}$ is calculated as:

$$S_{FLAIR} - T_{FLAIR}\left(\phi_b^{-1}\right)$$

where $\phi_b: S  \leftrightarrow \underset{b}{\leftrightsquigarrow} T$ is the transform
which maps from the individual subject space to the
template space and $T_{FLAIR}$ is the FLAIR template component.  Also,
to take advantage of the bilateral symmetry of the normal brain (in terms of both shape
and intensity), and the fact that the presence of WMHs violates that assumption,
we use the symmetric templates to compute the contralateral intensity
differences as an additional intensity feature.  For the FLAIR component, this contralateral
difference image is calculated from

$$S_{FLAIR} - S_{FLAIR}\left(\phi_b^{-1}\left(\phi_R\left(\phi_b\right)\right)\right)$$

where $\phi_R$ denotes a horizontal reflection perpendicular to the mid-sagittal plane of
the symmetric template.

The segmentation probability images described above are used as feature images to provide a
spatial context for the random forest model prediction step.  Additional spatial contextual
feature images include the distance maps [@maurer2003] based on the csf, gray matter, and
deep gray matter images.  These latter images are intended to help distinguish white matter
hyperintensities from false positives induced by the partial voluming at the gray/white
matter interface.  A third set of images are based on the voxel location within the
space of the template.  The T1 image of the subject is registered to the T1 template
component using a B-spline variant [@Tustison:2013ac] of the well-known ANTs Symmetric
Normalization (SyN) algorithm [@Avants:2011ab].  Since the inverse transform is also
derived as part of the registration process, we can warp the voxel index locations
back to the space of the individual subject.    Note that this is similar in motivation to the work
of [@Anbeek:2004aa].  However, this previous work lacks the normalization to the standard
coordinate system provided by the template to dramatically improve spatial specificity
across all subjects.

### Stacked (concatenated) random forests for improved segmentation performance

In previous brain tumor segmentation work [@Tustison:2015aa], it was demonstrated that a
concatenated supervised approach, whereby the prediction output from the first random forest
model serves as partial input for a second random forest model, can significantly improve
segmentation performance.  We do the same thing for the work described here.  The Stage 1
feature images of the training data (as described previously) are used to construct the
Stage 1 model.  The training data Stage 1 features are then used to produce the voxelwise
voting maps via the Stage 1 model.  All the Stage 1 features plus the Stage 1 voting maps
are used as input to the Stage 2 model.  In addition, we use the Stage 1 voting maps as
tissue priors for a second application of the Atropos maximum aposteriori algorithm with an
additional Markov Random Field spatial prior (MAP-MRF) [@Avants:2011aa].  However, for
the second stage we use all three aligned preprocessed images for a multivariate
segmentation.  The resulting seven posterior probability images constitute a third additional
feature image set for Stage 2.

### Code and data availability

As pointed out in a recent comprehensive multiple sclerosis lesion segmentation review
[@Garcia-Lorenzo:2013aa], although the number of algorithms reported in the literature
is quite extensive, there were only four publicly available segmentation algorithms
at the time of writing of which none are based on supervised learning.  As we did for
our brain tumor segmentation algorithm [@Tustison:2015aa], all of the code described in
this work is publicly available through the open-source ANTs/ANTsR toolkits.  Through
ANTsR (an add-on toolkit which, in part, bridges ANTs and the R statistical project) we
use the \texttt{randomForest} package [@liaw2002] using the default settings with
2000 trees per model and 500 randomly selected samples per label per image.

In addition, similar to our previous offering [^1], we plan on creating
a self-encapsulated example to showcase the proposed methodology.  The fact that
the data will also be made available through the FITBIR repository along
with the manual labelings will facilitate reproducibility on the part of the reader
as well as any interest in extending the proposed framework to other data sets.

[^1]: https://github.com/ntustison/ANTsAndArboles


### Evaluation protocol overview

In order to evaluate the protocol described, we performed a leave-one-out evaluation using
the data acquired from the 24 subjects described above.  Initial processing included the creation
of all Stage 1 feature images for all subjects.  The initial brain segmentation of each T1 image and the
manual white matter hyperintensity tracings were combined to provide the truth labels
for the training data.  The truth labels are the seven anatomical regions given above.

The leave-one-out procedure is as follows:

* Create Stage 1 feature images for all 24 subjects.
* For each of the 24 subjects:
    + sequester the current subject and corresponding feature images.
    + construct the Stage 1 random forest model from the remaining 23 subjects.
    + apply the Stage 1 random forest model to the feature images of the 23 training subjects.
    + the previous step produces the Stage 1 voting maps for all seven labels.
    + for each of the 23 subjects, perform a Bayesian-based segmentation with an MRF spatial
      prior using the seven voting maps are used as additional tissue priors.
    + construct the Stage 2 random forest model from all the Stage 1 feature images,
      seven voting maps, and seven posterior probability maps from the previous step.
    + send the sequestered subject through the random forest models for both stages.
    + compare the final results with the manually-defined white matter hyperintensity
      regions.


<!--

* Evaluation
    * Proper context
        * We only have manual labelings from a single radiologist (
        * TBI white matter hyperintensities are more difficult to segment than MS lesions
            * individual lesions are smaller
            * lesion load is typically smaller
            * not prone to enhancement
            * less distinct from surrounding tissue ?
    * Despite the doubts regarding the efficacy of a typical segmentation validation,
      our contribution is useful because
         * the total segmentation framework is publicly available within the ANTs/ANTsR
           framework
         * although only a single site is analyzed, the feature images are site-agnostic
              * we plan to apply the current RF models directly to the other site data
              * we can then build the training database further by enlisting other experts
         * Is this the first work exploring segmentation of white matter hyperintensities in TBI?
         * The data (including manual tracings) will be made available as part of the FITBIR
           effort.

-->

# Results

## Ranking feature importance

After performing the leave-one-out evaluation described at the end of the previous section,
we calculated the \texttt{MeanDecreaseAccuracy} feature values for each of the 24 subjects $\times$
2 models per subject $=48$ total models.  This measure (per feature, per model) is calculated
during the out-of-bag phase of the random forest model construction and quantifies the decrease
in prediction accuracy from omitting the specified feature.  In other words, this quantity
helps determine the importance of a particular feature and, although we save such
efforts for future work, this information provides us with guidance for future feature
pruning and/or additions.

![Average \texttt{MeanDecreaseAccuracy} plots generated from the creation of all 24 random
forest models for both Stage 1 and Stage 2 during the leave-one-out evaluation.  These plots
are useful in providing a quantitative assessment of the predictive importance of each feature.
The horizontal error bars provide the $95^{th}$ percentile (i.e., $1.96 \times \sigma$) and illustrate the
stability of the feature importance across the leave-one-out models.](Figures/averageLeaveOneOut.png)

The resulting rankings for both Stages are given in Figure 4 where the values for the
separate stages are averaged over the entire corresponding model set.  In addition, we
track the variance for each feature over all models to illustrate the stability of
the chosen features during the evaluation.  This latter information is illustrated as
horizontal errors bars providing the $95^{th}$ percentile (i.e., $1.96 \times \sigma$).
Note that the reader can cross reference Table 1 for identifying corresponding feature types
and names.

One can also use these measurements as a type of sanity check.  For example, from the Stage
1  plot, one can see that the \texttt{MeanDecreaseAccuracy} values for the location indices in the
anterior-posterior direction (i.e., \texttt{TemplateIndicesWarped1}) are greater than
those for either the inferior-superior (i.e., \texttt{TemplateIndicesWarped0}) or the
left-right (i.e., \texttt{TemplateIndicesWarped0}) directions in the space of the symmetric
template.  This is intuitive since, as discussed previously, manifestation of TBI white
matter hyperintensities can often be confused with higher intensities at the
periventricular caps in normal subjects [@Neema:2009aa] whereas there does not seem to
be contralateral bias in manifestation of white matter hyperintensities in TBI.

Additionally, it is interesting to note some of the other top performing features for Stage 1.
The contralateral difference FLAIR image is  highly discriminative over the set of
evaluation random forest models.  This accords with the known clinical relevance of
FLAIR images for identifying white matter hyperintensities and the fact that such
pathology does not manifest symmetrically in both hemispheres.  Interestingly, the
posterior maps for the deep gray matter are extremely important for accurate white matter
hyperintensity segmentation.  Perhaps the spatial specification of deep
gray matter aids in the removal of false positives.  Inspection of the bottom of the
plots demonstrates the lack of discriminating features associated with the
T1 image which is also well-known in the clinical literature.

As described earlier, for Stage 2, we used the output random forest voting maps from Stage
1 as both features themselves and as priors for input to a Bayesian-based segmentation with
an additional MRF spatial prior.  In Figure 4, the voting maps are labeled as
"\texttt{RFStage1VotingMaps}" where the final numeral is associated with the brain
parenchymal labeling given previously.  Similarly, the additional RF prior segmentation
feature probability maps are labeled as "\texttt{RFBrainSegmentationPosteriors}".
The Stage 2 feature importance plot follows similar
trends as that for Stage 1 with the T1 images not contributing much to the identification
of white matter hyperintensity voxels.  The initial voting maps from Stage 1 are extremely
important with the top 3 being the estimated locations of the 1) gray matter, 2) white matter, and
3) white matter hyperintensities.  Since these tissue type can be conflated based on intensity
alone it is intuitive that such features would be important.

## White matter hyperintensity segmentation evaluation

In Figure 5 are the segmentation comparisons derived from manual segmentations of the same
data.  Despite the large variability characteristic with manual labelings in related fields
[@Grimaud:1996aa;@styner2008;@Garcia-Lorenzo:2013aa], such labelings are characteristic of
current clinical practices and the methodology proposed herein is readily adapted to refinements
in training data.  On the left of Figure 5 are the improvement in Dice values over all white
matter hyperintensities when comparing the segmentations between the two stages.  Performing
the second round of supervised learning improves Dice values.  One can also note from the
right side of Figure 5 that the total lesion load volume illustrates a few subjects that are
severe outliers in terms of the number of false positives.  The second round helps to
correct this issue.

![Comparison with manual delineation of white matter hyperintensities.  On the left are the
calculate Dice values over all white matter hyperintensities.  Note the improvement
in the Dice metric from the employment of the Stage 2 component of the processing pipeline.
(Right) Similar results can be seen by comparing the total lesion load volume between manual
and automated detection strategies.  Although some outliers are found after the Stage 2
processing in a couple subjects, the number of outliers caused by false positives is
significantly with the second stage processing.](Figures/llvAndDice.png)


\clearpage

# References
