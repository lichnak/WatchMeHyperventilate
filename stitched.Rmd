---
output:
  word_document:
    fig_caption: true
  pdf_document:
    fig_caption: true
    latex_engine: xelatex
    keep_tex: yes
header-includes:
   - \usepackage{booktabs}
   - \usepackage[final]{changes}
   - \usepackage[font={small},labelfont=bf,labelsep=colon]{caption}
   - \linespread{1.2}
   - \usepackage[compact]{titlesec}
   - \usepackage{enumitem}
   - \usepackage{tikz}
   - \def\checkmark{\tikz\fill[scale=0.4](0,.35) -- (.25,0) -- (1,.7) -- (.25,.15) -- cycle;}
   - \setlist{nolistsep}
   - \titlespacing{\section}{2pt}{*0}{*0}
   - \titlespacing{\subsection}{2pt}{*0}{*0}
   - \titlespacing{\subsubsection}{2pt}{*0}{*0}
   - \setlength{\parskip}{3pt}
   - \setremarkmarkup{(#2)}
   - \definechangesauthor[name={Nick Tustison}, color=red]{nt}
   - \definechangesauthor[name={James Stone}, color=magenta]{js}
   - \definechangesauthor[name={Lisa Wilde}, color=cyan]{lw}
   - \definechangesauthor[name={Andy Mayer}, color=green]{am}
   - \definechangesauthor[name={Harvey Levin}, color=blue]{hl}
   - \definechangesauthor[name={Brian Taylor}, color=purple]{bt}
   - \definechangesauthor[name={David Tate}, color=orange]{dt}
bibliography: references.bib
csl: council-of-science-editors.csl
fontsize: 11pt
mainfont: Georgia
geometry: margin=1.0in
---

<!--
   - \setlength{\parskip}{3pt}
   - \setlength{\topsep}{0pt}
   - \setlength{\partopsep}{0pt}
   - \setlength{\itemsep}{0pt}
   - \setlength{\floatsep}{0pt}
   - \setlength{\intextsep}{2pt}
   - \setlength{\abovecaptionskip}{2pt}
   - \setlength{\belowcaptionskip}{0pt}
-->


<style type="text/css">
body,
code.bash{
  font-size: 8px;
}
pre {
  font-size: 8px
}
</style>



```{r setup, include=FALSE}
knitr::opts_chunk$set( cache=TRUE )
```

\pagenumbering{gobble}

# Abstract

White matter hyperintensities (WMHs) are foci of abnormal signal
intensity in white matter regions seen with magnetic resonance imaging
(MRI). WMHs are associated with normal aging and have shown prognostic
value in neurological conditions such as traumatic brain injury (TBI).
The impracticality of manually quantifying these lesions limits their
clinical utility and motivates the utilization of machine learning
techniques for automated segmentation workflows.  Herein, we develop a
concatenated random forest framework with image features for
segmenting WMHs in a TBI cohort. The framework is built upon the
Advanced Normalization Tools (ANTs)  and ANTsR toolkits.  MR
(3D FLAIR, T2-, and T1-weighted) images from 24 service members and
veterans scanned in the Chronic Effects of Neurotrauma Consortiumâ€™s
(CENC) observational study were acquired. Manual annotations were
employed for both training and evaluation using a leave-one-out
strategy.  Lesion load and overlap evaluative comparisons are
complimented by feature rankings which showcase the utility of the
concatenated approach.  Our findings suggest supervised learning methods
may be applied to quantify WMHs on routine brain imaging. Paired with
correlative outcome data, supervised learning methods may allow for
identification of imaging features predictive of diagnosis and prognosis
in individual TBI patients.

\clearpage
<!--
A couple notes in response to comments:

[David Tate, Comment 15]:  Stupid question, but why not show the same subject and slice for both for a better comparison?

NT:  I see what he is saying and probably agree.

[David Tate, Comment 28]:  Maybe this could go in a Figure as a flow chart??

NT:  Flow charts are great and I included a couple as Figure 5 in my tumor paper.  However, they take a long time to make correctly and I do not want to commit to producing one unless it is absolutely necessary.

[Andy Mayer, Comment 30]: It will be difficult to see this font for labeling on Y axis at current size/resolution. You may also consider alerting your reader directly that the magnitudes of the scales are very different for stage 1 versus stage 2 in the legend or scale them to be similar.

NT:  Comparing these two plots in Figure 4 in terms of their absolute MeanDecreaseAccuracy
is meaningless so coordinating the scales is not important.

[Andy Mayer, Comment 34]:  A reviewer is likely to ask for some sort of reliability rating on the labeling of the lesions.

NT:  I agree with this but unless somebody else is willing to manually segment the WMHs,
then there is not really much we can do other than point to other papers which have looked
at reliability.

[David Tate, Comment 37]:  Seems like we are missing a picture.  That is the football player in me, but it seems like we need a picture that shows the manual compared to the automated at each stage if possible.

NT:  We could do this but I do not think that such images in publications are that meaningful as they typically result from heavy selection bias.  I did do something similar
for my brain segmentation paper where I showed multiple slices (skipped every 10, or something like that) for each subject in the challenge cohort but tumors are obviously much bigger and can be displayed in this manner.

[David Tate, Comment 39]:  I would would move these comments down to a limitation like paragraph, otherwise it minimizes the cool findings.

NT:  I have no opinion on this.  Do what you think is best.

[Andy Mayer, Comment 40]:  I do not know if you can include any of this data (even one subject). It would be great to demonstrate that your algorithm worked on data collected on another scanner since the intensities are likely to be very different.

NT:  As I mentioned to you previously, I think this is a great idea and I would be happy to include it but how do we showcase this unless somebody is willing to annotate data from these other sites.  We could include a picture of a single subject but how persuasive that is will be reviewer-dependent.  Personally, I would not be persuaded as the showing the results of a single subject is very prone to selection bias.


-->








# Introduction

## White matter hyperintensities in TBI

\textcolor{blue}{White matter hyperintensities (WMHs) are foci of abnormally increased signal intensity seen within white matter regions within the cerebrum and brainstem on fluid attenuation inversion recovery (FLAIR) magnetic resonance imaging (MRI) sequences.
WMHs are a frequent finding following traumatic brain injury (TBI) and have been correlated with functional outcome and injury severity in both pediatric} [@Bigler:2013aa;@Smitherman:2016aa] \textcolor{blue}{and adult} [@Marquez-de-la-Plata:2007aa;@Moen:2014aa;@Ding:2008aa;@Pierallini:2000aa] \textcolor{blue}{populations.}

\textcolor{blue}{Further research involving WMHs has shown that regional distribution and volume of WMHs have been shown to possess prognostic value in the TBI patient} [@Pierallini:2000aa;@Weiss:2008aa;@Smitherman:2016aa;@Levin:1988aa]\textcolor{blue}{. Specifically, lesion volume in corpus callosum correlates with functional scores in the acute phase following injury, while lesion volume in frontal lobes correlates with scores at 1 year following injury} [@Pierallini:2000aa]\textcolor{blue}{.
Further, volume of FLAIR lesions within the corpus
callosum, brainstem, and thalamus in patients with severe TBI correlates
with Glasgow Outcome-Extended (GOS-E) scores---a numeric groupwise assessment used to
classify ``outcome'' in TBI patients where ``outcome'' refers to the
spectrum of possible prognoses from death to disability to recovery.} [@Moen:2014aa]\textcolor{blue}{. Additionally,
in patients who are comatose following severe TBI
the regional distribution of FLAIR lesions within the pons, midbrain, hypothalamus, basal forebrain, parietal, temporal, occipital lobes, and insula along with the observation of grasping or chewing behavior are associated with poor outcome} [@Weiss:2008aa].

\textcolor{blue}{Despite the above findings which demonstrate that WMHs have potential prognostic value, they are not routinely employed as a diagnostic measure in clinical practice.  Performing a comprehensive manual counting of number and distribution of lesions in the clinical setting is simply not practical. As such, the development of automated methods for the rapid identification and quantification of WMHs within individual patients may allow for identification of correlative patterns between WMH number, volume, distribution, and disease state. Further, the development of such lesion quantification approaches may allow for the practical inclusion of this type of information within routine radiological practice.  In this work, we present an automated framework for quantification of WMHs in
multi-modal MRI using the random forest machine learning technique.}


## Random forests for WMH segmentation

<!--
Machine learning and pattern recognition techniques have seen increased application
for various medical image analysis workflows (see, for example, the annual
Workshop on Machine Learning in Medical Imaging held in conjunction with the Medical
Image Computing and Computer-Aided Intervention (MICCAI) international meeting).
Popular techniques such as support vector machines and neural networks have been applied
successfully to clinically relevant imaging tasks such as supervised image segmentation
(e.g., [@Bauer:2011aa]) and diagnostic prediction (e.g., [@Tong:2014aa;@Liu:2013aa]).
Facilitating the current employment of such techniques are the number of available imaging
data sets [@Van-Horn:2014aa] and the public availability of data science packages such as
SciPy [@scipy] and the R project for statistical computing [@R] and their associated
extensions.
-->

The random forests framework [@breiman2001] is a popular machine learning technique that has demonstrated significant utility for supervised segmentation tasks (e.g.,
normal human brain segmentation [@yi2009]) and other computer vision applications
(e.g., [@viola2005]).
\textcolor{blue}{Random forest-based paradigms have been successfully employed in the
delineation of other neuropathologies} [@geremia2011;@Pustina:2016aa;@geremia2012;@bauer2012;@zikic2012;@Tustison:2015aa]
\textcolor{blue}{for both single and multi-modal acquisition protocols.}

<!--
Of note, these
latter random forest approaches for brain tumor segmentation have performed well in recent
international competitions established in response to the lack of objective comparisons between segmentation algorithms (i.e.,  the Multimodal Brain Tumor Segmentation (BRATS) challenge was initiated in 2012 [@Menze:2015aa].
-->

Random forests are conceptually straightforward [@breiman2001].
\textcolor{blue}{The basic component of
the random forest paradigm is the ``decision tree'' often represented by a flowchart or
graph where internal nodes represent ``tests'', or decisions, and the edges represent the outcome of those tests.  The final, or end, nodes represent the various classsifications produced by traversal through the decision tree.  For the proposed application, individual
voxels (and their corresponding feature values) are introduced at the root of a particular
decision tree and traverse the edges and internal nodes ultimately ending up at one of
the classification nodes according to the tests at each internal node.  A single random
forest model will consist of many such trees (often refered to as an ``ensemble'').}
\textcolor{blue}{Although decision trees had been extensively studied, the success of employing collections of such weak learners for boosting machine learning performance
(e.g., AdaBoost)} [@schapire1990;@freund1997]
\textcolor{blue}{influenced the similarly sytled conglomeration of decision trees into ``forests'' with randomized node optimization} [@ho1995;@amit1997].
\textcolor{blue}{Finally, Breiman} [@breiman2001]
\textcolor{blue}{improved accuracy by random sampling of training data (i.e., ``bagging'') resulting
in the current random forest technique applied here.}
\textcolor{blue}{As voxels and their feature values are ``pushed'' through each decision tree in the forest,  votes for each label are accumulated and converted to probability values for all classification possiblilities at
each voxel location.}

In this work, we develop a concatenated random forest framework with a
feature image set (both spatial and intensity-based)
for segmenting WMHs in a large TBI cohort.
The entire framework is built on the well-known open-source
Advanced Normalization Tools (ANTs)[^i1] and ANTsR[^i2] toolkits.
Further motivating this research is the availability of several large publicly available  imaging data sets that permits testing reproducibility of this automated routine for WMH segmentation and quantification.

[^i1]: https://github.com/stnava/ANTs
[^i2]: https://github.com/stnava/ANTsR

# Materials and Methods

## Imaging

MR images utilized for this initial report were acquired from a single scanner involved in the Chronic Effects of Neurotrauma Consortiumâ€™s (CENC) observational study (see Walker et al., this issue). Briefly, participants were Operation Iraqi Freedom/Operation Enduring Freedom (OIF/OEF) era Service Members and Veterans between the ages of 18-60 years with prior combat exposure and deployment(s). The feature images \textcolor{blue}{were derived from MR acquisitions of} 26 subjects aged 39.6 $\pm$ 8.1 years (range 28--58 years). Within this cohort, 24 (92%) were considered positive for TBI based upon the potential concussive events (PCE) interview process described in detail in Walker et al., this issue). \textcolor{blue}{All lesions were isolated in the white matter of the cerebrum.  Table 1 provides a descriptive statistical summary of the variation in lesion
load across the selected cohort.}

<!--

\input{trainingData.tex}

-->

Images were acquired on a Philips 3.0T Ingenia system with an 8-channel SENSE head coil (Philips Medical Systems, Best, Netherlands).  3D FLAIR sequences were acquired with a turbo spin echo inversion recovery sequence with the following parameters:  repetition time (TR) = 4800 ms, echo time (TE) = 325 ms, inversion time (TI) = 1650 ms; 170 sagittal slices with a 1.2 mm slice thickness, 256 $\times$ 256 acquisition matrix, and 256 $\times$ 256 mm FOV.  3D T1-weighted sequences were acquired with a fast field echo (FFE) sequence with the following parameters:  TR = 6.8 ms, TE = 3.2 ms, echo train length (ETL) = 240; Flip angle = 9$^\circ$, 170 sagittal slices with a 1.2 mm slice thickness, 256x240 acquisition matrix, and 256 $\times$ 256 mm FOV.  In addition, 3D T2-weighted images were acquired with a turbo spin echo sequence with the following parameters:  TR = 2500 ms, TE = 245 ms, ET: = 133; 170 sagittal slices with a 1.2 mm slice thickness, 256 $\times$ 256 acquisition matrix, and 256 x 256 mm FOV.

\textcolor{blue}{The first author (J. R. S.) performed the manual WMH tracings for all 26
subjects.  J. R. S. is a radiologist certified by the American Board of Radiology, with a certificate of advanced qualification in vascular and interventional radiology, over 18 years of research experience in TBI, and 6 years of clinical imaging experience.  All
multi-modal MR dicom image slices were converted to the nifti file format} [^1].
\textcolor{blue}{Given the
utility of the FLAIR sequence in detecting white matter lesions in TBI}  [@Marquez-de-la-Plata:2007aa]\textcolor{blue}{, all nifti image volumes for each subject were rigidly aligned to the FLAIR image of that subject using the ANTs software} [@Avants:2014aa] \textcolor{blue}{.  The normalized MRI volumes were then provided to
J. R. S. who traced each lesion using the ITK-SNAP tool} [@Yushkevich:2006aa]
\textcolor{blue}{
which has multi-image overlay capabilities for visualizing all modalities in all three
canonical views.}

[^1]: http://nifti.nimh.nih.gov/nifti-1


## Quantitative analysis

\textcolor{blue}{Figure 1 provides a graphical overview of the proposed workflow.  The major components
include offline generation of symmetric multimodal templates, the creation of
feature images from the training data which are then employed for statistical
prediction using a concatenated random forest framework.  This framework involves
the use of two random forest models where the outcome (i.e., the tissue
probability estimates) of the first RF model application,
which we denote as ``Stage1 '', is used as input (along with the original set of
feature images) to a refinement RF model segmentation which we denote as ``Stage 2''.
Once these offline steps
are performed, a new, unsegmented subject can then be processed using the proposed pipeline.}

<!--

![\textcolor{blue}{Workflow illustration for the proposed pipeline.  Processing of the multi-modal
input MRI for a single subject, using the multi-modal symmetric template, results in
the generation of the feature images.  These feature images are used as input to the
Stage 1 RF model producing the initial RF probability map estimates.  The Stage 1
voting maps, the original feature images, and the Stage 2 RF model result in the
final voting maps which includes the WMH probability estimate.  Note that the RF models
are constructed once from a set of training data which are processed using the
same feature-construction pipeline as the single-subject input MRI.}](Figures/wmhPipeline.png)

-->

### Symmetric multi-modal templates

\textcolor{blue}{Following} [@Tustison:2014ab] \textcolor{blue}{and} [@Tustison:2015aa], \textcolor{blue}{optimally derived templates
serve for both brain tissue segmentation (for the derivation of tissue prior probability maps) and generation of asymmetry feature images.
For this work we use the multi-modal data available from the public MMRR data set}
[@landman2011]\textcolor{blue}{.  We used all 46 multi-modal acquisitions of that study to produce a multi-modal template according to the procedure described in} [@Avants:2010aa] \textcolor{blue}{which
results in a mean (in terms of both shape and intensity) multivariate template representing the entire cohort.  Mid-canonical slices of the FLAIR, T1, and T2 components are illustrated in Figure 2.}

<!--
![Canonical views of the mutlivariate, bilaterally symmetric template constructed
from the MMRR data set [@landman2011] (only shown are the FLAIR, T1, and T2 modalities---
the components relevant for this work).  Template construction is detailed in
[@Tustison:2015aa].  These images are important for specific asymmetry-based
features.](Figures/MMRR.png)

-->


### Feature images for WMH segmentation


\textcolor{blue}{
Crucial to these supervised segmentation approaches are the creation and selection of
``features'' as input (i.e., feature images constructed from the training data)
in conjunction with expertly identified structures of interest
(i.e., WMHs) for model construction.}  For the targeted application in this work,
tissue classification is performed at the voxelwise level.  In other words, each voxel
within the region of interest is sent through the ensemble of decision trees and receives
a set of classification votes from each tree thus permitting a regression or classification
solution.  Since this procedure is performed at the voxelwise level, intensity information
alone is insufficient for good segmentation performance due to the lack of spatial context.
For example, as pointed out in [@Neema:2009aa], higher intensities can be found at the
periventricular caps in normal subjects which often confounds automated lesion detection
algorithms.  Other potential confounds include MR signal inhomogeneity and noise.  Therefore,
even though machine learning and pattern recognition techniques are extremely powerful and
have significant potential, just as crucial to outcome is the creative construction and
deployment of salient feature images which we detail below.

<!--

\input{featureImagesTable.tex}

-->

Supervised methodologies are uniquely characterized, in part, by the feature images that
are used to identify the regions of interest.  In Table 2, we provide a list and basic
categorization of the feature images used for the initial (i.e., Stage 1---more on the use
of multiple random forest stages below) segmentation of the WMHs.
In addition Figure 3 provides a representation of a set of feature images for a single
subject analyzed in this work.  Note that in this work we categorize the brain parenchyma
with seven labels:

* cerebrospinal fluid (label 1),
* gray matter (label 2),
* white matter (label 3),
* deep gray matter (label 4),
* brain stem (label 5),
* cerebellum (label 6), and
* white matter hyperintensities (label 7).

<!--

![Representation of Stage 1 feature images for subject 01C1019.  The
FLAIR, T1-, and T2-weighted images are rigidly pre-aligned
[@Avants:2014aa] to the space of the FLAIR image.  The three modality images are then preprocessed
(N4 bias correction [@Tustison:2010ac] and adaptive denoising [@Manjon:2010aa]) followed by
application of standard ANTs brain extraction and $n$-tissue segmentation protocols using
the MMRR symmetric template and corresponding priors [@Tustison:2014ab] applied to the T1 image.
The feature images are then generated for voxelwise input to the RF model which results in
the voting maps illustrated on the right.  This gives a probabilistic classification of
tissue type.  Not shown are the probability and voting images for the brain stem and
cerebellum.](Figures/featureImages.png)

-->

As mentioned previously, input for each subject comprises FLAIR, T1-, and T2-weighted
acquisitions.  The T1 and T2 images are rigidly registered to the FLAIR image using
the open-source Advanced Normalization Tools (ANTs) [@Avants:2014aa].  The aligned images
are then preprocessed using the denoising algorithm of [@Manjon:2010aa] followed by
N4 bias correction [@Tustison:2010ac] which are then normalized to the intensity
range $[0,1]$.  Although we could have used an alternative intensity standardization
algorithm (e.g., [@nyul2000]), we found that a simple linear rescaling produced better results similar to previous work[@Tustison:2015aa].

<!--

![Sample FLAIR acquisition image slices showing both manual and random forest
segmentations for both stages obtained during the leave-one-out evaluation.  Manual
segmentations were performed by one of the authors and provided the ground
truth WMH labels for training the random forest models.](Figures/sampleResults.png)

-->

The T1 image is then processed via the ANTs brain
extraction and normal tissue segmentation pipelines [@Tustison:2014ab].
  The result is a mask delineating the brain parenchyma and probabilistic estimates of the
CSF, gray matter, white matter, deep gray matter, brain stem, and
cerebellum [@Avants:2011aa].  These provide the expertly annotated labels for the
first six tissue labels given above.  Tissue prior probability maps for segmentation
are from multi-model optimal symmetric shape/intensity templates [@Tustison:2015aa] created from the public MMRR data set  [@landman2011] (cf Figure 2).


Feature values include the preprocessed FLAIR, T1, and T2 image voxel intensities.
We also calculate a set of neighborhood statistics (mean, standard deviation, and skewness) feature images using
a Manhattan radius of one voxel given the typical size
of individual WMHs. For each of the preprocessed
images, we calculate the difference in intensities with the corresponding warped template
component.  Previous success in the international brain tumor segmentation
competition [@Menze:2015aa] was based on an important set of intensity features that were created
from multi-modal templates mentioned previously [@Tustison:2015aa] and listed in Table 2.  We employ the
same strategy here.

<!--
For example, the template
difference feature image for the FLAIR image, $S_{FLAIR}$ is calculated as:

$$S_{FLAIR} - T_{FLAIR}\left(\phi_b^{-1}\right)$$

where

$$\phi_b: S  \leftrightarrow \underset{b}{\leftrightsquigarrow} T$$

is the transform
which maps from the individual subject space to the
template space and $T_{FLAIR}$ is the FLAIR template component.
-->

To take advantage of the gross bilateral symmetry of the normal brain (in terms of both shape and intensity), and the fact that WMHs do not generally manifest symmetrically across hemispheres,
we use the symmetric templates to compute the contralateral intensity
differences as an additional intensity feature.

<!--
For the FLAIR component, this contralateral
difference image is calculated from

$$S_{FLAIR} - S_{FLAIR}\left(\phi_b^{-1}\left(\phi_R\left(\phi_b\right)\right)\right)$$

where $\phi_R$ denotes a horizontal reflection perpendicular to the mid-sagittal plane of
the symmetric template.
-->

The segmentation probability images described above are used as feature images to
provide a spatial context for the random forest model prediction step.  Additional spatial contextual
feature images include the distance maps [@maurer2003] based on the csf, gray matter, and
deep gray matter images.  These latter images are intended to help distinguish white matter
hyperintensities from false positives induced by the partial voluming at the gray/white
matter interface.  A third set of images are based on the voxel location within the
space of the template.
\textcolor{blue}{Similar feature images were used in}
[@Anbeek:2004aa]
\textcolor{blue}{although, unlike the proposed framework, this previous work lacks
normalization to the standard
coordinate system provided by the template to dramatically improve spatial specificity
across all subjects.  To generate these images, the T1 image of each subject is
registered to the T1 template component using a B-spline variant} [@Tustison:2013ac]
\textcolor{blue}{of the well-known ANTs Symmetric Normalization (SyN) algorithm} [@Avants:2011ab].
\textcolor{blue}{Using the derived transforms, the template coordinate images are warped back to the space of the individual subject.}


### Stacked (concatenated) random forests for improved segmentation performance

In previous brain tumor segmentation work [@Tustison:2015aa], it was demonstrated that a
concatenated supervised approach, whereby the prediction output from the first random forest
model serves as partial input for a second random forest model, can significantly improve
segmentation performance.  We do the same thing for the work described here where we employ two stacked random forests (or two "stages").  The Stage 1
feature images of the training data (as described previously) are used to construct the
Stage 1 model.  The training data Stage 1 features are then used to produce the voxelwise
"voting maps" (i.e., the classification count of each decision tree for each tissue label) via the Stage 1 random forest model.  All the Stage 1 features plus the Stage 1 voting maps
are used as input to the Stage 2 model.  In addition, we use the Stage 1 voting maps as
tissue priors (i.e., probabilistic estimates of the tissue spatial locations) for a second application of the $6$-tissue segmentation algorithm with an
additional Markov Random Field spatial prior (MAP-MRF) [@Avants:2011aa].
\textcolor{blue}{In order to maximize the spatial information for the $n$-tissue segmentation process following the voxelwise RF classification of Stage 1, we use
all three aligned preprocessed images for multivariate segmentation during the
second stage.}
The resulting seven posterior probability images constitute a third additional feature image set for Stage 2.

### Implementation

As pointed out in a recent comprehensive lesion segmentation review
[@Garcia-Lorenzo:2013aa], although the number of algorithms reported in the literature
is quite extensive, there were only four publicly available segmentation algorithms
at the time of writing this article.  In contrast to the current work, none are based on supervised learning.  As we did for
our brain tumor segmentation algorithm [@Tustison:2015aa], all of the code described in
this work is publicly available through the open-source ANTs/ANTsR toolkits.  Through
ANTsR (an add-on toolkit which, in part, bridges ANTs and the R statistical project) we
use the _randomForest_ package [@liaw2002] using the default settings with
2000 trees per model and 500 randomly selected samples per label per image.
Note that we saw little variation in performance when these parameters were changed (i.e. up to 1000 random samples and as little as 1000 trees) which is consistent with our previous experience.

In addition, similar to our previous offering [^2], we plan on creating
a self-encapsulated example to showcase the proposed methodology
\textcolor{blue}{which will also be available on github.}[^3]  The fact that
the data will also be made available through the Federal Interagency Traumatic Brain Injury Research (FITBIR) repository along
with the manual labelings will facilitate reproducibility on the part of the reader
as well as any interest in extending the proposed framework to other data sets.

[^2]: https://github.com/ntustison/ANTsAndArboles

[^3]: https://github.com/ntustison/WatchMeHyperventilate

### Evaluation protocol overview

In order to evaluate the protocol described, we performed a leave-one-out evaluation using
the data acquired from the 24 subjects described above.  Initial processing included the creation of all Stage 1 feature images for all subjects.  The initial brain segmentation of each T1 image and the manual white matter hyperintensity tracings were combined to provide the truth labels for the training data.  The ``truth'' labels are the seven anatomical regions given above.

The leave-one-out procedure is as follows:

* Create Stage 1 feature images for all 24 subjects.
* For each of the 24 subjects:
    + sequester the current subject and corresponding feature images.
    + construct the Stage 1 random forest model from the remaining 23 subjects.
    + apply the Stage 1 random forest model to the feature images of the 23 training subjects.
    + the previous step produces the Stage 1 voting maps for all seven labels.
    + for each of the 23 subjects, perform a Bayesian-based segmentation with an
      MRF spatial
      prior using the seven voting maps as additional tissue priors.
    + construct the Stage 2 random forest model from all the Stage 1 feature images,
      seven voting maps, and seven posterior probability maps from the previous step.
    + send the sequestered subject through the random forest models for both stages.
    + compare the final results with the manually-defined white matter hyperintensity
      regions.


# Results

## Ranking feature importance

After performing the leave-one-out evaluation,
we calculated the _MeanDecreaseAccuracy_ feature values for each of the 24 subjects $\times$
2 models per subject $=48$ total models.  This measure (per feature, per model) is calculated
during the out-of-bag phase of the random forest model construction and quantifies the decrease
in prediction accuracy from omitting the specified feature.  In other words, this quantity
helps determine the importance of a particular feature and, although we save such
efforts for future work, this information provides us with guidance for future feature
pruning and/or additions.

<!--

![Average _MeanDecreaseAccuracy_ plots generated from the creation of all 24 random
forest models for Stage 1 during the leave-one-out evaluation.  These plots
are useful in providing a quantitative assessment of the predictive importance of each feature.
Features are ranked in descending order of importance.
The horizontal error bars provide the $95^{th}$ percentile
 and illustrate the
stability of the feature importance across the leave-one-out models.
At this initial stage only 31 features images are used.](Figures/averageLeaveOneOutStage1.png)



![Average _MeanDecreaseAccuracy_ plots generated from the creation of all 24 random
forest models for Stage 2 during the leave-one-out evaluation.  These plots
are useful in providing a quantitative assessment of the predictive importance of each feature.
Features are ranked in descending order of importance.
The horizontal error bars provide the $95^{th}$ percentile and illustrate the
stability of the feature importance across the leave-one-out models.
We augment the 31 feature images from the first stage by adding an additional
7 voting maps and 7 segmentation posteriors from application of the Bayesian-based
segmentation for a total of 45 images for the second stage.](Figures/averageLeaveOneOutStage2.png)

-->

The resulting rankings for both Stages are given in Figures 5 and 6 where the values for the
separate stages are averaged over the entire corresponding model set.  In addition, we
track the variance for each feature over all models to illustrate the stability of
the chosen features during the evaluation.  This latter information is illustrated as
horizontal errors bars providing the $95^{th}$ percentile
Note that the reader can cross reference Table 1 for identifying corresponding feature types
and names.

<!--
One can also use these measurements as a type of sanity check.  For example, from the Stage
1  plot, one can see that the _MeanDecreaseAccuracy_ values for the location indices in the
anterior-posterior direction (i.e., _TemplateIndicesWarped1_) are greater than
those for either the inferior-superior (i.e., _TemplateIndicesWarped2_) or the
left-right (i.e., _TemplateIndicesWarped0_) directions in the space of the symmetric
template.
-->

Additionally, it is interesting to note some of the other top performing features for Stage 1.
The contralateral difference FLAIR image is  highly discriminative over the set of
evaluation random forest models (see Figure 7).  This accords with the known clinical relevance of
FLAIR images for identifying white matter hyperintensities and the fact that such
pathology does not typically manifest symmetrically in both hemispheres.  Interestingly, the
posterior maps for the deep gray matter are extremely important for accurate white matter
hyperintensity segmentation.  Perhaps the spatial specification of deep
gray matter aids in the removal of false positives.  Inspection of the bottom of the
plots demonstrates the lack of discriminating features associated with the
T1 image which is also well-known in the clinical literature.

<!--

![(a) FLAIR image slice illustrating WMHs which have been manually delineated.
The region around the WMHs is enlarged (b) in the original FLAIR and the
(c) contralateral FLAIR difference image.](Figures/FLAIRcontralaleteralWithLesionsAlternate.png)

-->

As described earlier, for Stage 2, we used the output random forest voting maps from Stage
1 as both features themselves and as priors for input to a Bayesian-based segmentation with
an additional MRF spatial prior.  In Figure 6, the voting maps are labeled as
"_RFStage1VotingMaps_" where the final numeral is associated with the brain
parenchymal labeling given previously.  Similarly, the additional RF prior segmentation
feature probability maps are labeled as "_RFBrainSegmentationPosteriors_".
The Stage 2 feature importance plot follows similar
trends as that for Stage 1 with the T1 images not contributing much to the identification
of white matter hyperintensity voxels.  The initial voting maps from Stage 1 are extremely
important with the top 3 being the estimated locations of the 1) gray matter, 2) white matter, and
3) white matter hyperintensities.  Since these tissue type can be conflated based on intensity
alone it is intuitive that such features would be important.

## White matter hyperintensity segmentation evaluation

In Figure 8 are the segmentation comparisons derived from manual segmentations of the same
data.  Despite the large variability characteristic with manual labelings in related fields
[@Grimaud:1996aa;@styner2008;@Garcia-Lorenzo:2013aa], such labelings are characteristic of
current clinical practices and the methodology proposed herein is readily adapted to refinements
in training data.


<!--
i.e.,

$$ Dice = 2 \frac{\sum_r|S_r \cap T_r|}{\sum_r|S_r| + |T_r] } $$
-->

On the left of Figure 8 are the improvement in Dice values [@tustison2009],
over all white matter hyperintensities when comparing the segmentations between the two stages
where the sum is taken over all individually labeled manual, $T_r$, and automated, $S_r$, lesions and $\cap$
represents the intersection between the manual/automated lesion pair.  Performing
the second round of supervised learning improves these Dice values.  One can also note from the
right side of Figure 7 that the total lesion load volume illustrates a few subjects that are
severe outliers in terms of the number of false positives.  The second round helps to
correct this issue.

<!--

![Voxelwise comparison with manual delineation of white matter hyperintensities.  On the left are the
calculated Dice values over all white matter hyperintensities.  Note the improvement
in the Dice metric from the employment of the Stage 2 component of the processing pipeline.
(Right) Similar results can be seen by comparing the total lesion load volume between manual
and automated detection strategies.  Although some outliers are found after the Stage 2
processing in a couple subjects, the number of outliers caused by false positives is
decreased significantly with the second stage processing.](Figures/llvAndDice.png)

-->

# Discussion

<!-- Nick could you add some detail here on how this technique compares
to other automated or semi automated approaches for WMH detection? -->

<!--

* Evaluation * Proper context * We only have manual labelings from a
single radiologist ( * TBI white matter hyperintensities are more
difficult to segment than MS lesions * individual lesions are smaller *
lesion load is typically smaller * not prone to enhancement * less
distinct from surrounding tissue ? * Despite the doubts regarding the
efficacy of a typical segmentation validation, our contribution is
useful because * the total segmentation framework is publicly available
within the ANTs/ANTsR framework * although only a single site is
analyzed, the feature images are site-agnostic * we plan to apply the
current RF models directly to the other site data * we can then build
the training database further by enlisting other experts * Is this the
first work exploring segmentation of white matter hyperintensities in
TBI? * The data (including manual tracings) will be made available as
part of the FITBIR effort.

-->


The current communications describes a supervised statistical learning
methodology for identifying WHMs within multimodal MR brain imaging.
This effort utilized information acquired from the manual segmentation
of WMHs from FLAIR images to help build two-stage ensembles of decision
trees for the automated identification of these lesions. Although only a
single expert was used to produce the manual labelings, our intent is to
further refine the proposed paradigm by crowdsourcing with feedback from
other experts who interact with both the data and methodology.  Also, we
recognize that only a single site was used for evaluating the proposed
framework.  However, we are currently processing other site data with
the models developed for this work and the results look promising since
the developed features are site-agnostic.

As far as we know, this is the first report utilizing a novel random
forest approach to identify WMHs in a cohort of TBI patients.  TBI WMHs
tend to be more difficult to segment than MS lesions as the former tend
to be smaller with an overall smaller lesion load.  Also, enhancement
protocols with the former tend to be less successful than with the
latter.  As mentioned previously, the work in MS lesion segmentation is
extensive with a handful of techniques being publicly available.

<!--
Our
framework is also available as open-source as part of well-known
neuroimaging tools which easily allows for additions/extensions but is
also, as far as we know, the first random forest-based technique
available for such application.
-->

Two major meta-analyses of WMHs have been published covering the periods
prior to 2010 [@Debette:2010aa] and after [@Kloppenborg:2014aa]. The earlier meta-analysis
covered 53 longitudinal studies that included samples of high-risk
populations, i.e., patients selected for a specific disease or condition
such as hypertension, whereas other studies recruited samples of the
general population. Longitudinal studies of samples representative of
the general population are more relevant to the focus of the present
paper. Debette & Markus [@Debette:2010aa] found that the presence of
WMHs was related to subsequent cognitive decline, a higher risk of
developing dementia, stroke, and of mortality. Lesion volume at baseline
was also predictive of cognitive decline. Limitations of this
meta-analysis include heterogeneity in the method of measuring WMHs;
some studies used automated volumetric measurement, whereas others used
a visual rating scale. The studies analyzed by Debette & Markus were
limited to the occurrence of one of the aforementioned conditions which
they analyzed by hazard ratios.

The more recent meta-analysis by Kloppenborg et al.
[@Kloppenborg:2014aa] of 23 cross-sectional studies reporting MRI and
concurrent neuropsychological results in patients with heterogeneous
diagnoses but without previously diagnosed cognitive impairment, found
that WMHs were associated with cognitive deficit (effect size of -0.10,
95% CI: -0.13 to -0.08) after controlling for age. These studies also
differed in the metric used to measure the WMHs, including volume, % of
total intracranial volume, and a visual rating score. The effect size
for the association with cognitive deficit in these cross-sectional
studies did not differ significantly across various cognitive domains or
the method of measuring lesion volume.  Among eight longitudinal studies
analyzed by Kloppenborg et al that included a follow-up MRI and also
controlled for age, the effect size for the association of progression
in WMHs and cognitive impairment was -0.16 (95% CI:-0.27 to -0.09). This
association was stronger for attention and executive function than for
memory and processing speed. Although baseline WMHs were predictive of
cognitive deficit at follow-up in the seven studies which did not repeat
MRI, the effect size was smaller [-0.10 (95% CI: 0.13 to -0.05) than in
the longitudinal studies that calculated progression in WMHs. In
summary, progression of WMHs seen on repeat MRI has a stronger relation
to cognitive deficit than concurrent imaging findings. These
meta-analyses support the rationale for repeating an MRI in patients
younger than 50 years whose initial scan shows WMHs.

Despite the
above-described associations between WMHs, cognitive decline, increased
risk of developing dementia, and mortality, these lesions receive little
attention in current clinical workflows. When reported in a standard
neuroradiologist interpretation, they are typically handled as
incidental findings and are assigned little clinical significance. This
likely reflects the impracticality of performing a detailed assessment
of number, volume, and distribution within a qualitative
neuroradiologist interpretation as well as the lack of correlative
information on how the presence and distribution of these lesions may
inform a diagnosis and prognosis in the appropriate clinical setting. To
date, automated or semi-automated tools for the detection of WMHs have
lacked the specificity and efficiency for the mining of large-scale
datasets to generate highly granular data on whether these lesions
possess any true diagnostic or prognostic value in the setting of a
specific disease process. The present communication describes a
supervised statistical learning tool that is appropriate for the
application to such large-scale datasets.

The currently described tool is just one example of how "supervised
learning" algorithms might be applied to aid in the diagnosis of TBI and
other disease processes through the specific identification of features
predictive of a given disease state. It is an important demonstration of
the potential power of these analytical approaches in the rapid but
comprehensive mining of information from neuroimaging examinations.
Supervised learning algorithms are presently employed across a wide
variety of settings for the rapid identification of predictive imaging
features [@Plis:2014aa;@Suk:2015aa;@Li:2014aa;@Liu:2015aa]. Automobile
manufacturers utilize these types of approaches to equip self-driving
vehicles to recognize and respond to unique external surroundings
through the identification of visual information sufficiently similar to
previously assimilated training data [@HadsellSBESKML09;@FarabetCNL12].
Similarly, in the context of the neuroimaging assessments, deep learning
approaches may allow for the rapid identification of information
predictive of disease state in an individual patient. These approaches
have been applied to the segmentation of macroscopically visible
structures [@Plis:2014aa;@Suk:2015aa;@Li:2014aa;@Liu:2015aa].
Additionally, these approaches might be applied to the interrogation of
imaging data in the individual patient with a primary quantitative
output metrics to include sequences such as diffusion tensor imaging
(DTI) and its variants, functional connectivity, perfusion weighted
imaging, and cortical thickness assessments. At present, these advanced
neuroimaging sequences are confined to cohort-based research studies due
to the lack of available analytical tools to assess the information in
the setting of the individual patient [@Mayer:2014aa]. Application of
deep learning approaches in the context of data with primary
quantitative outputs will require large scale normative and disease
specific databases. Building these large scale imaging libraries is
resource intensive and requires a multi-center approach with harmonized
scanners between sites and correlative non-imaging clinical data. Large
scale TBI data is becoming increasingly available through activities
such as the Chronic Effects of Neurotrauma Consortium (CENC),
Transforming Research and Clinical Knowledge in TBI (TRACK-TBI),
Collaborative European Neurotrauma Effectiveness Research in TBI
(CENTER-TBI), Department of Defense Alzheimerâ€™s Disease Neuroimaging
Initiative (DOD-ADNI), and other data being consolidated through FITBIR.
In concert with any available high quality normative neuroimaging data,
deep learning algorithms may be well positioned to help transform how
neuroimaging is interpreted for the clinical management of patients with
this disease process.

\clearpage

## Acknowledgements

The authors wish to acknowledge all other members of
the CENC Neuroimaging Steering Committee and CENC leadership (Drs. David
X. Cifu, Ramon Diaz-Arrastia, and Rick Williams) for their support. We
also gratefully acknowledge the assistance of Tracy Nolen, Chris Siege
and Kevin Wilson. We would also like to thank the study participants and
their family members. This project was jointly supported by the
Department of Defense (W81XWH-13-2-0095), the U.S. Department of
Veterans Affairs (I01 CX001135 and I01 RX 002174), as well as USUHS
Grant HU 0001-08-0001.


## Declaration of Interest/Disclaimer

The authors report no financial
disclosures or conflicts of interest. The views expressed here are those
of the authors and do not necessarily reflect the official policy of
position of the Department of the Navy, Department of Defense, nor the
U.S. Government. This work was prepared as a part of official duties;
Title 17 USC Â§105 provides that Copyright protection under this title is
not available for any work of the U.S. Government. Title 17 USC Â§101
defines a US Government work as a work prepared by a military service
member of employee of the US Government as part of that personâ€™s
official duties.


\clearpage

<!-- \listofchanges

\clearpage -->

# References

# Figure Captions

__Figure 1:__ \textcolor{blue}{Workflow illustration for the proposed pipeline.  Processing of the multi-modal
input MRI for a single subject, using the multi-modal symmetric template, results in
the generation of the feature images.  These feature images are used as input to the
Stage 1 RF model producing the initial RF probability map estimates.  The Stage 1
voting maps, the original feature images, and the Stage 2 RF model result in the
final voting maps which includes the WMH probability estimate.  Note that the RF models
are constructed once from a set of training data which are processed using the
same feature-construction pipeline as the single-subject input MRI.}

__Figure 2:__  Canonical views of the mutlivariate, bilaterally symmetric template constructed
from the MMRR data set [@landman2011] (only shown are the FLAIR, T1, and T2 modalities---
the components relevant for this work).  Template construction is detailed in
[@Tustison:2015aa].  These images are important for asymmetry-based
features.


__Figure 3:__  Representation of Stage 1 feature images for subject 01C1019.  The
FLAIR, T1-, and T2-weighted images are rigidly pre-aligned
[@Avants:2014aa] to the space of the T1 image.  The three modality images are then preprocessed
(N4 bias correction [@Tustison:2010ac] and adaptive denoising [@Manjon:2010aa]) followed by
application of standard ANTs brain extraction and $n$-tissue segmentation protocols using
the MMRR symmetric template and corresponding priors [@Tustison:2014ab] applied to the T1 image.
The feature images are then generated for voxelwise input to the RF model which results in
the voting maps illustrated on the right.  This gives a probabilistic classification of
tissue type.  Not shown are the probability and voting images for the brain stem and
cerebellum.

__Figure 4:__  Sample FLAIR acquisition image slices showing both manual and random forest
segmentations for both stages obtained during the leave-one-out evaluation.  Manual
segmentations were performed by one of the authors and provided the ground
truth WMH labels for training the random forest models.

__Figure 5:__ Average _MeanDecreaseAccuracy_ plots generated from the creation of all 24 random
forest models for Stage 1 during the leave-one-out evaluation.  These plots
are useful in providing a quantitative assessment of the predictive importance of each feature.
Features are ranked in descending order of importance.
The horizontal error bars provide the $95^{th}$ percentile
and illustrate the
stability of the feature importance across the leave-one-out models.
At this initial stage only 31 feature images are used.

__Figure 6:__  Average _MeanDecreaseAccuracy_ plots generated from the creation of all 24 random
forest models for Stage 2 during the leave-one-out evaluation.  These plots
are useful in providing a quantitative assessment of the predictive importance of each feature.
Features are ranked in descending order of importance.
The horizontal error bars provide the $95^{th}$ percentile
 and illustrate the
stability of the feature importance across the leave-one-out models.
We augment the 31 feature images from the first stage by adding an additional
seven voting maps and 7 segmentation posteriors from application of the Bayesian-based
segmentation for a total of 45 images for the second stage.

__Figure 7:__ (a) FLAIR image slice illustrating WMHs which have been manually delineated.
The region around the WMHs is enlarged (b) in the original FLAIR and the
(c) contralateral FLAIR difference image.

__Figure 8:__ Voxelwise comparison with manual delineation of white matter hyperintensities.
On the left are the
calculated Dice values over all white matter hyperintensities.  Note the improvement
in the Dice metric from the employment of the Stage 2 component of the processing pipeline.
(Right) Similar results can be seen by comparing the total lesion load volume between manual
and automated detection strategies.  Although some outliers are found after the Stage 2
processing in a couple subjects, the number of outliers caused by false positives is
decreased significantly with the second stage processing.

\clearpage

