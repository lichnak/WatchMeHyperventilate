
# Results


## White matter hyperintensity segmentation evaluation

\textcolor{blue}{In Figure 8 we provide the segmentation evaluations derived from the leave-one-out evaluation
of the previously described TBI data.  These performance measures include sensitivity,
positive predictive value, $F_1$ score, and relative volume difference.  The three lesion
size ranges over which these measures are computed to illustrate the variation
in performance with lesion size.  Smaller lesions ($< 12$ voxels) are more difficult
to identify which is why the sensitivity is widely varied over the cohort vs. the largest
set of voxels ($> 28$ voxels).   The first three measures are based on the identification of
entire lesions.  The relative volume difference provides a direct assessment of how accurate
the volumetric estimate is when comparing the manually identified lesions versus the
automatically predicted lesions.}

<!--

In Figure 8 are the segmentation comparisons derived from manual segmentations of the same
data.  Despite the large variability characteristic with manual labelings in related fields
[@Grimaud:1996aa;@styner2008;@Garcia-Lorenzo:2013aa], such labelings are characteristic of
current clinical practices and the methodology proposed herein is readily adapted to refinements
in training data.

On the left of Figure 8 are the improvement in Dice values [@tustison2009],
over all white matter hyperintensities when comparing the segmentations between the two stages
where the sum is taken over all individually labeled manual, $T_r$, and automated, $S_r$, lesions and $\cap$
represents the intersection between the manual/automated lesion pair.  Performing
the second round of supervised learning improves these Dice values.  One can also note from the
right side of Figure 7 that the total lesion load volume illustrates a few subjects that are
severe outliers in terms of the number of false positives.  The second round helps to
correct this issue.

-->


<!--

![Evaluation measures for the leave-one-out protocol of the described protocol in the Methods
section:  (a) sensitivity, (b) positive predictive value, (c) $F_1$ score, and (d) relative
volume difference.   The three quantile ranges include the following lesion volume ranges:
$[3-12)$, $[12-28)$, and $[28-551]$ based on the manually-derived lesion volumes.  These
measures are computed for both Stages.  Overall improvement is seen as the
second Stage RF model is applied for all three quantile ranges.](Figures/evaluationResults.png)

-->


## Ranking feature importance

After performing the leave-one-out evaluation,
we calculated the _MeanDecreaseAccuracy_ feature values for each of the 24 subjects $\times$
2 models per subject $=48$ total models.  This measure (per feature, per model) is calculated
during the out-of-bag phase of the random forest model construction and quantifies the decrease
in prediction accuracy from omitting the specified feature.  In other words, this quantity
helps determine the importance of a particular feature and, although we save such
efforts for future work, this information provides us with guidance for future feature
pruning and/or additions.

<!--

![Average _MeanDecreaseAccuracy_ plots generated from the creation of all 24 random
forest models for Stage 1 during the leave-one-out evaluation.  These plots
are useful in providing a quantitative assessment of the predictive importance of each feature.
Features are ranked in descending order of importance.
The horizontal error bars provide the $95^{th}$ percentile
 and illustrate the
stability of the feature importance across the leave-one-out models.
At this initial stage only 31 features images are used.](Figures/averageLeaveOneOutStage1.png)



![Average _MeanDecreaseAccuracy_ plots generated from the creation of all 24 random
forest models for Stage 2 during the leave-one-out evaluation.  These plots
are useful in providing a quantitative assessment of the predictive importance of each feature.
Features are ranked in descending order of importance.
The horizontal error bars provide the $95^{th}$ percentile and illustrate the
stability of the feature importance across the leave-one-out models.
We augment the 31 feature images from the first stage by adding an additional
7 voting maps and 7 segmentation posteriors from application of the Bayesian-based
segmentation for a total of 45 images for the second stage.](Figures/averageLeaveOneOutStage2.png)

-->

The resulting rankings for both Stages are given in Figures 5 and 6 where the values for the
separate stages are averaged over the entire corresponding model set.  In addition, we
track the variance for each feature over all models to illustrate the stability of
the chosen features during the evaluation.  This latter information is illustrated as
horizontal errors bars providing the $95^{th}$ percentile
Note that the reader can cross reference Table 1 for identifying corresponding feature types
and names.

<!--
One can also use these measurements as a type of sanity check.  For example, from the Stage
1  plot, one can see that the _MeanDecreaseAccuracy_ values for the location indices in the
anterior-posterior direction (i.e., _TemplateIndicesWarped1_) are greater than
those for either the inferior-superior (i.e., _TemplateIndicesWarped2_) or the
left-right (i.e., _TemplateIndicesWarped0_) directions in the space of the symmetric
template.
-->

Additionally, it is interesting to note some of the other top performing features for Stage 1.
The contralateral difference FLAIR image is  highly discriminative over the set of
evaluation random forest models (see Figure 7).  This accords with the known clinical relevance of
FLAIR images for identifying white matter hyperintensities and the fact that such
pathology does not typically manifest symmetrically in both hemispheres.  Interestingly, the
posterior maps for the deep gray matter are extremely important for accurate white matter
hyperintensity segmentation.  Perhaps the spatial specification of deep
gray matter aids in the removal of false positives.  Inspection of the bottom of the
plots demonstrates the lack of discriminating features associated with the
T1 image which is also well-known in the clinical literature.

<!--

![(a) FLAIR image slice illustrating WMHs which have been manually delineated.
The region around the WMHs is enlarged (b) in the original FLAIR and the
(c) contralateral FLAIR difference image.](Figures/FLAIRcontralaleteralWithLesionsAlternate.png)

-->

As described earlier, for Stage 2, we used the output random forest voting maps from Stage
1 as both features themselves and as priors for input to a Bayesian-based segmentation with
an additional MRF spatial prior.  In Figure 6, the voting maps are labeled as
"_RFStage1VotingMaps_" where the final numeral is associated with the brain
parenchymal labeling given previously.  Similarly, the additional RF prior segmentation
feature probability maps are labeled as "_RFBrainSegmentationPosteriors_".
The Stage 2 feature importance plot follows similar
trends as that for Stage 1 with the T1 images not contributing much to the identification
of white matter hyperintensity voxels.  The initial voting maps from Stage 1 are extremely
important with the top 3 being the estimated locations of the 1) gray matter, 2) white matter, and
3) white matter hyperintensities.  Since these tissue type can be conflated based on intensity
alone it is intuitive that such features would be important.
