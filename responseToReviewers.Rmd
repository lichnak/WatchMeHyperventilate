---
output:
  word_document:
    fig_caption: true
  pdf_document:
    fig_caption: true
    latex_engine: xelatex
    keep_tex: yes
header-includes:
   - \usepackage{booktabs}
   - \usepackage[final]{changes}
   - \usepackage[font={small},labelfont=bf,labelsep=colon]{caption}
   - \linespread{1.2}
   - \usepackage[compact]{titlesec}
   - \usepackage{enumitem}
   - \usepackage{tikz}
   - \def\checkmark{\tikz\fill[scale=0.4](0,.35) -- (.25,0) -- (1,.7) -- (.25,.15) -- cycle;}
   - \setlist{nolistsep}
   - \titlespacing{\section}{2pt}{*0}{*0}
   - \titlespacing{\subsection}{2pt}{*0}{*0}
   - \titlespacing{\subsubsection}{2pt}{*0}{*0}
   - \setlength{\parskip}{3pt}
   - \setremarkmarkup{(#2)}
bibliography: references.bib
csl: council-of-science-editors.csl
fontsize: 12pt
mainfont: Georgia
---

<style type="text/css">
body,
code.bash{
  font-size: 8px;
}
pre {
  font-size: 8px
}
</style>



```{r setup, include=FALSE}
knitr::opts_chunk$set( cache=TRUE )
```

# Response to reviewers

_\textcolor{blue}{We appreciate the time spent by the editors and reviewers in
assessing our manuscript.  Please see below for a point-by-point response to the
issues raised.}_

## Reviewer 1

Thank you for the opportunity to review the paper "Supervised learning
technique for the automated identification of white matter
hyperintensities in traumatic brain injury". In this study, the authors
present a machine learning algorithm for automated segmentation of white
matter hyperintensities, a form of white matter degeneration visible in
FLAIR-MRI that is observed in a wide range of clinical syndromes, and
even in healthy controls. The method proposed by the authors relies on
training random forests to learn the relationship between voxel
intensities in a set of feature images derived from multimodal MRI (T1,
T2, FLAIR) and lesions drawn manually by an expert. Since the method uses
examples to learn what constitutes a lesion, this is correctly considered
a supervised method. The method is applied on a set of 24 patients with
clinically confirmed traumatic brain injury, and results are obtained
with a leave-one-out cross validation.

Overall, the method proposed by the authors is innovative and thoughtful,
and has great potential for bridging the gap between research findings
and clinical needs. The method uses a series of cutting edge solutions to
the segmentation problem: (1) multimodal imaging inputs, which is known
to increase segmentation accuracy, (2) random forests, which are an
excellent tool for finding multivariate nonlinear relationships, (3)
voxel neighborhood information, which provide contextual information for
each voxel, and (4) an algorithm that improves the segmentation in
stages. However, the manuscript itself, to my opinion, is not well
focused and needs significant improvement. Below are my specific comments
in support of this.

> _\textcolor{blue}{We thank the reviewer for the generally positive assessment of our work.  We also
> appreciate the detailed critique below to help us improve specific aspects of the
> presentation.}_

Major comments:

1. The biggest issue I had while reading the manuscript is the lack of a
coherent theme of what this paper is about. The authors span their exposÃ©
from multiple sclerosis to the automobile industry, without stating why
these links to other diseases (or industries) have any relevance. It
appears in some parts that the closest disease with similar white matter
lesions is multiple sclerosis, but this is not clearly stated, nor the
two types of lesions are compared. It is, therefore, unclear why counting
how many MS lesion segmentation methods are publicly available is of any
importance. When explaining methods, the authors mention the utility of
support vector machines, or the existence of a python package called
SciPy. Yet, it is unclear why these things have any importance, unless
the authors make connections to their topic/method.

> _\textcolor{blue}{We reduced the introduction to limit the clinical motivation to a
TBI context and removed mention of multiple sclerosis to remove any assumption of
disease similarity (although the segmentation approaches can be similar).  We also
removed the paragraph dealing with publicly available software for neuroimaging analysis.
}_

2. Second, the manuscript has no results. All the results section is focused
on talking about feature ranking, which by the way is explained in the
Results section instead of the Methods section. The most important
results (the prediction accuracy of automated segmentation), are not
mentioned in the manuscript but are only plotted in Figure 7. My advice
is to put the focus of the results section on accuracy, i.e., give
precise dice values and perhaps add other measures (metric displacement,
Hausdorf distance, sensitivity, specificity, etc.). Also, the gain in
accuracy from stage 1 to stage 2 cannot be guessed by looking at a plot,
the authors must provide a statistical comparison. When investigating
accuracy, the error in lesion size should be reported, both in terms of
volume and in terms of individual lesions counts (i.e. out of 10 lesions
9 were found, 1 was missed, etc.). This information is crucial to
clinicians, if the authors foresee the use of the method in a clinical
setting, as it seems from the discussion. Beside adding results to the
manuscript, it is equally important to give some results in the abstract.
The abstract must be self-sufficient in reporting all the major points of
the paper.

> _\textcolor{blue}{We completely reorganized the results and discussion
section to reflect the new evaluation.  In addition, we added a synopsis
of these results to the abstract.}_

3. Third, there is no information about the manual lesion tracing procedure.
Were lesion drawn on FLAIR or were other modalities used as well? If
FLAIR was used as reference it is not surprising that FLAIR emerges as
one of the top predictive modalities.

> _\textcolor{blue}{We added the following to the Methods section:}_

> \textcolor{blue}{The first author (J. R. S.) performed the manual WMH tracings for all 26  subjects.  J. R. S. is a radiologist certified by the American Board of Radiology, with a certificate of advanced qualification in vascular and interventional radiology, over 18 years of research experience in TBI, and 6 years of clinical imaging experience.  All multi-modal MR dicom image slices were converted to the nifti file format. All nifti image volumes for each subject were rigidly aligned to the T1 image of that subject using the ANTs software} [@Avants:2014aa] \textcolor{blue}{.  The normalized MRI volumes were then provided to J. R. S. who traced each lesion using the ITK-SNAP tool} [@Yushkevich:2006aa]
> \textcolor{blue}{ which has multi-image overlay capabilities for visualizing all modalities in all three canonical views.}

> Descriptive statistics on the lesions are also necessary: how big were the
> lesions, how many lesions were found in each patient (the range 1-20 is not sufficiently
> informative), where were the lesions located? This information helps
> understand why, for example, brain stem or cerebellum labels were not
> that important for achieving good lesion predictions.

> _\textcolor{blue}{We added the following sentence to the opening paragraph of the
Imaging subsection of the Methods section:}_

> \textcolor{blue}{All lesions were isolated in the white matter of the cerebrum.
Table 1 provides a descriptive statistical summary of the variation in lesion load across the selected cohort.}

> _\textcolor{blue}{as well as the corresponding table:}_

\input{trainingData.tex}

\clearpage

4. Fourth, although the authors claim the method is available, I couldn't
find any link for the public. Note, it would be equally important if the
publication of the method online is associated with proper documentation
on how a new (naive) user can apply it.

> _\textcolor{blue}{Our methodological publication history demonstrates that we are
very supportive of open science and have released both code and data in conjunction
with these publications in public forums, such as github.  However, permission to
publicly release the data for this data has not yet been obtained and so we removed
the mention of public availability.  However, when we do get permission, it will
be posted to the github repository associated with this manuscript
(https://github.com/ntustison/WatchMeHyperventilate), which we mention in the text,
for future readers.
}_

Minor comments:

5. In the abstract, the authors mention the creation of tailored features
for segmenting WMHs. My understanding is that the method proposed by the
authors has no tailoring (if we think of tailoring as custom cutting to
WMH needs).

> _\textcolor{blue}{We removed the word ``tailor'' in its various forms in the
manuscript to avoid the misreading described by the reviewer.}_

> There was no feature selection process all the features were
> included as predictors.

> _\textcolor{blue}{Although feature selection is mentioned in the manuscript, nowhere
do we mention or imply any type of computational feature selection.  There was
a feature selection process in that we selected ones from the myriad feature images that
one can possibly produce based on our targeted application, i.e. WMHs.}_

> A similar pitfall if found on pg. 6 ln 56, where
> the manuscript reads ``Crucial to these supervised segmentation approaches
> are the creation and selection of features as input in conjunction with
> expertly identified structures.'' What are the structures identified by
> the expert in this study?

> _\textcolor{blue}{For this particular application, white matter hyperintensities
are the structure of interest.  We have re-emphasized this point by writing:
}_

> \textcolor{blue}{Crucial to these supervised segmentation approaches are the creation and selection of
``features'' as input (i.e., feature images constructed from the training data)
in conjunction with expertly identified structures of interest
(i.e., WMHs) for model construction.}

6. The methods section is very confusing. The section "Feature images for
WMH segmentation" starts with no explanation of what is Stage 1. The
logical flow would require template registration explained first, and all
feature computation performed later, and finally RF stages can be
explained with the available features.

> _\textcolor{blue}{We added Figure 1 which gives an overview of the basic workflow.
>   It can be seen below in response to item 2 of Reviewer 2.  We reference
>   this figure numerous times in the text as a visual explanatory aid.}_
> _\textcolor{blue}{We also added a paragraph at the beginning of the "Quantitative analysis" subsection
>   which gives an overview of the methods section including an description of Stage 1 and Stage2.}_
>
>   \textcolor{blue}{Figure 1 provides a graphical overview of the proposed workflow.  The major components
include offline generation of symmetric multimodal templates, the creation of
feature images from the training data which are then employed for statistical
prediction using a concatenated random forest framework.  This framework involves
the use of two random forest models where the outcome (i.e., the tissue
probability estimates) of the first RF model application,
which we denote as ``Stage1 '', is used as input (along with the original set of
feature images) to a refinement RF model segmentation which we denote as ``Stage 2''.
Once these offline steps
are performed, a new (i.e., unsegmented) subject can then be processed using the proposed pipeline.}
>
> _\textcolor{blue}{We also added a subsection explaining the symmetric multimodal template:}_
>
> \textcolor{blue}{Following} [@Tustison:2014ab] \textcolor{blue}{and} [@Tustison:2015aa], \textcolor{blue}{optimally derived templates
> serve for both brain tissue segmentation (for the derivation of tissue prior probability maps) and generation of asymmetry feature images.
> For this work we use the multi-modal data available from the public MMRR data set}
> [@landman2011]\textcolor{blue}{.  We used all 46 multi-modal acquisitions of that study to produce a multi-modal template according to the procedure described in} [@Avants:2010aa] \textcolor{blue}{which
> results in a mean (in terms of both shape and intensity) multivariate template representing the entire cohort.  Mid-canonical slices of the FLAIR, T1, and T2 components are illustrated in Figure 2.}
>
> _\textcolor{blue}{These changes complement the edits made in response to other review items.}_


> The pipeline also seem to be
> repetitive, the N4 correction is mentioned in ln. 26 and then again in
> ln. 43, which sounds like it was performed twice. Tissue segmentation is
> mentioned in ln. 39, then it is stated is a Bayesian method (ln 45), and
> then it is referred to as Atropos in the next page.

> _\textcolor{blue}{The two mentions of N4 are due to the fact that they are associated
with two distinct pipelines:  1) preparation of the images for extracting feature values
and 2) brain extration and $n$-tissue segmentation.  We rewrote the section in question
to avoid any confusing redundancy:}_

> _\textcolor{blue}{The T1 image is then processed via the ANTs brain
extraction and normal tissue segmentation pipelines}_ [@Tustison:2014ab]
> _\textcolor{blue}{.  The result is a mask delineating the brain
parenchyma and probabilistic estimates of the CSF, gray matter, white matter,
deep gray matter, brain stem, and cerebellum}_ [@Avants:2011aa]
> _\textcolor{blue}{.  These provide the expertly annotated labels for the
first six tissue labels given above.  Tissue prior probability maps for segmentation
are from multi-model optimal symmetric shape/intensity templates}_ [@Tustison:2015aa]
> _\textcolor{blue}{created from the public MMRR data set}_  [@landman2011]
> _\textcolor{blue}{(cf Figure 3).}_



> It is unclear what is ``the first set of images'' in pg. 9, or if there is a second set.

> _\textcolor{blue}{We clarified this confusion by changing the sentence in question from}_

> \textcolor{blue}{To model the intensity information the first set of images simply includes the
> preprocessed and normalized intensity FLAIR, T1, and T2 image voxel values.}

> _\textcolor{blue}{to}_

> \textcolor{blue}{Feature values include the preprocessed FLAIR, T1, and T2 image voxel intensities.}

> Also, mathematical formulas seem superfluous, particularly since it takes more
> space to explain the formula than to say in plain English that
> transformation matrices were applied to bring subject's images in
> template space.

> _\textcolor{blue}{Done.  We removed the mathematical formulas.}_

7. Random forests are explained in a way that can be understood only by
readers who already know how they work; a new reader (especially a
clinician) would not be able to understand the method. For example, data
pushed onto a tree is does not mean much, unless the reader knows what is
an identification tree.

> _\textcolor{blue}{
We revised the explanation of random forests as follows:}_

> \textcolor{blue}{The basic component of
the random forest paradigm is the ``decision tree'' often represented by a flowchart or
graph where internal nodes represent ``tests'', or decisions, and the edges represent the outcome of those tests.  The final, or end, nodes represent the various classsifications produced by traversal through the decision tree.  For the proposed application, individual
voxels (and their corresponding feature values) are introduced at the root of a particular
decision tree and traverse the edges and internal nodes ultimately ending up at one of
the classification nodes according to the tests at each internal node.  A single random
forest model will consist of many such trees (often refered to as an ``ensemble'').}
> \textcolor{blue}{Although decision trees had been extensively studied, the success of employing collections of such weak learners for boosting machine learning performance
(e.g., AdaBoost)} [@schapire1990;@freund1997]
>  \textcolor{blue}{influenced the similarly sytled conglomeration of decision trees into ``forests'' with randomized node optimization} [@ho1995;@amit1997].
\textcolor{blue}{Finally, Breiman} [@breiman2001]
\textcolor{blue}{improved accuracy by random sampling of training data (i.e., ``bagging'') resulting
in the current random forest technique applied here.}
> \textcolor{blue}{As voxels and their feature values are ``pushed'' through each decision tree in the forest,  votes for each label are accumulated and converted to probability values for all classification possiblilities at
each voxel location.}

8. The relationship between WMH and GOS-E is mentioned in pg. 2 but the
reader is not informed what is GOS-E.
A similar issue is met few lines
after, where the ``outcome'' is mentioned, but there is no information what
is referred to as outcome.

> _\textcolor{blue}{The sentence in question reads:}_

> \textcolor{blue}{Further, volume of FLAIR lesions within the corpus
callosum, brainstem, and thalamus in patients with severe TBI correlates
with Glasgow Outcome-Extended (GOS-E) scores.} [@Moen:2014aa]

> _\textcolor{blue}{Although the full phrase corresponding to the acronym
in question is provided prior to the acronym in the text (along with an
explanatory reference), we have added the following clarification:}_

> \textcolor{blue}{Further, volume of FLAIR lesions within the corpus
callosum, brainstem, and thalamus in patients with severe TBI correlates
with Glasgow Outcome-Extended (GOS-E) scores} [@Moen:2014aa]
> \textcolor{blue}{---a numeric groupwise assessment used to
classify ``outcome'' in TBI patients where ``outcome'' refers to the
spectrum of possible prognoses from death to disability to recovery.}

9. In pg. 3 the authors propose that automated methods ``may allow for
identification of correlative patterns between WMH number, volume,
distribution, and disease state''. Some of these correlations have been
already identified in the literature, as the authors mention few lines
before. Moreover, the authors do not report number, volume, or
distribution of the lesions, to back up the utility of their method in
this regard.

> _\textcolor{blue}{We removed the sentence in question.  Also, as mentioned in
response to item 3, we added Table 1.}_

10. In pg. 4 ln 43, reads that the data is ``constructed.'' I don't think this
is the right verb.

> _\textcolor{blue}{We agree that the sentence in question could be read this way.
We have, therefore, clarified the sentence in question to read
``Once the ensemble of decision trees is constructed, data to be classified is ``pushed''
through each decision tree resulting in a single classification ``vote'' per tree.``}_

> A similar issue is in pg 5 ln 52 where it is stated that ``feature images
> consisted of 26 subjects.'' It is not ethical to consider participants as feature
> images.

> _\textcolor{blue}{This was a grammatical mistake, not a question of
ethics.  It has been fixed: ``The feature images
were derived from MR acquisitions of 26 subjects\ldots''}_

11. It is unclear to me the meaning of the sentence: ``Since the inverse
transform is also derived as part of the registration process, we can
warp the voxel index locations back to the space of the individual
subject which motivates similar work by others [43].''

> _\textcolor{blue}{The sentences were rewritten as follows:}_

> \textcolor{blue}{Similar feature images were used in}
[@Anbeek:2004aa]
> \textcolor{blue}{although, unlike the proposed framework, this previous work lacks
> normalization to the standard
> coordinate system provided by the template to dramatically improve spatial specificity
> across all subjects.  To generate these images, the T1 image of each subject is
> registered to the T1 template component using a B-spline variant} [@Tustison:2013ac]
> \textcolor{blue}{of the well-known ANTs Symmetric Normalization (SyN) algorithm} [@Avants:2011ab].
> \textcolor{blue}{Using the derived transforms, the template coordinate images are warped back to the space of the individual subject.}



12. Why was Stage 1 segmentation based only on T1, while Stage 2 segmentation
was based on multivariate segmentation using all three modalities?

> _\textcolor{blue}{We added the following clarification:}_

> \textcolor{blue}{In order to maximize the spatial information for the $n$-tissue segmentation
process following the voxelwise RF classification of Stage 1, we use all three
aligned preprocessed images for multivariate segmentation during the second stage.}

13. Similar to the feature ranking method, which is explain in Results, Dice
is also explained in Results.

> _\textcolor{blue}{We removed the equation for the Dice metric and described the
evaluation procedure in the Methods section.}_

> Also, it is unclear why finding which direction of space is informative for the
> segmentation process would be a ``sanity check.''

> _\textcolor{blue}{We removed this section to avoid unnecessary confusion.}_

14. The discussion starts with an ``intent to further refine the proposed
paradigm,'' and proceeds by mentioning other work currently being
performed which looks promising. The opening of the discussion with such
statements truly make the manuscript sound like an incomplete effort that
is not ready for publication.

> _\textcolor{blue}{We appreciate the positive view of our current work.
The full sentence in question is ``Although only a
single expert was used to produce the manual labelings, our intent is to
further refine the proposed paradigm by crowdsourcing with feedback from
other experts who interact with both the data and methodology.''
In our opinion, simply mentioning specific details regarding future work
does not mean that the manuscript ``sounds like an incomplete effort.''
Rather, it is simply an admission, similar to much of what is reported
in the literature, that our research program is ongoing.}_

15. The discussion also spends several paragraphs on defining literature that
shows how WMHs are related to cognitive performance, or how WMHs can be
applied in diagnosing TBI. Yet, this study makes no effort to test these
efforts in these 24 patients. Consequently, those paragraphs sound
wishful and speculative. Given the methodological nature of this paper, a
more appropriate discussion would perhaps focus on the comparison with
other methods in terms of accuracy, similarities, differences, etc.

> _\textcolor{blue}{We removed the paragraphs in question and added a
comparison discussion.}_

## Reviewer: 2

Interesting paper which offers those without a current background in
state-of-the-art brain analysis tools. A good introduction to their capabilities.

> _\textcolor{blue}{We thank the reviewer for the positive comments regarding our work.}_

1. However the authors do little to establish clinical utility of the
algorithm.

> _\textcolor{blue}{We appreciate
> the opportunity to clarify the precise nature of our contribution which is methodological
> (vs. clinical).  We have shortened the introduction to focus specifically on previous TBI
clinical research involving WMHs and then pointing to the need for automated
techniques to minimize the variability and time requirements of manual
segmentation of WMHs.  This would allow for large-scale studies and potentially more accurate
and reproducible quantitation.
}_

2. A graphical description of the pipeline would help most
readers to understand how this might get into the clinic.

> _\textcolor{blue}{Done.  We added the following figure as a graphical description of
> the pipeline to the manuscript:}_

![\textcolor{blue}{Workflow illustration for the proposed pipeline.  Processing of the multi-modal
input MRI for a single subject, using the multi-modal symmetric template, results in
the generation of the feature images.  These feature images are used as input to the
Stage 1 RF model producing the initial RF probability map estimates.  The Stage 1
voting maps, the original feature images, and the Stage 2 RF model result in the
final voting maps which includes the WMH probability estimate.  Note that the RF models
are constructed once from a set of training data which are processed using the
same feature-construction pipeline as the single-subject input MRI.}](Figures/wmhPipeline.png)

\clearpage

## References
