
# Discussion

<!-- Nick could you add some detail here on how this technique compares
to other automated or semi automated approaches for WMH detection? -->

<!--

* Evaluation * Proper context * We only have manual labelings from a
single radiologist ( * TBI white matter hyperintensities are more
difficult to segment than MS lesions * individual lesions are smaller *
lesion load is typically smaller * not prone to enhancement * less
distinct from surrounding tissue ? * Despite the doubts regarding the
efficacy of a typical segmentation validation, our contribution is
useful because * the total segmentation framework is publicly available
within the ANTs/ANTsR framework * although only a single site is
analyzed, the feature images are site-agnostic * we plan to apply the
current RF models directly to the other site data * we can then build
the training database further by enlisting other experts * Is this the
first work exploring segmentation of white matter hyperintensities in
TBI? * The data (including manual tracings) will be made available as
part of the FITBIR effort.

-->


The current communications describes a supervised statistical learning
methodology for identifying WHMs within multimodal MR brain imaging.
This effort utilized information acquired from the manual segmentation
of WMHs from FLAIR images to help build two-stage ensembles of decision
trees for the automated identification of these lesions. Although only a
single expert was used to produce the manual labelings, our intent is to
further refine the proposed paradigm by crowdsourcing with feedback from
other experts who interact with both the data and methodology.  Also, we
recognize that only a single site was used for evaluating the proposed
framework.  However, we are currently processing other site data with
the models developed for this work and the results look promising since
the developed features are site-agnostic.

As far as we know, this is the first report utilizing a novel random
forest approach to identify WMHs in a cohort of TBI patients.  TBI WMHs
tend to be more difficult to segment than MS lesions as the former tend
to be smaller with an overall smaller lesion load.  Also, enhancement
protocols with the former tend to be less successful than with the
latter.  As mentioned previously, the work in MS lesion segmentation is
extensive with a handful of techniques being publicly available.

<!--
Our
framework is also available as open-source as part of well-known
neuroimaging tools which easily allows for additions/extensions but is
also, as far as we know, the first random forest-based technique
available for such application.
-->

Two major meta-analyses of WMHs have been published covering the periods
prior to [@Debette:2010aa] and after 2010 [@Kloppenborg:2014aa].
Debette & Markus [@Debette:2010aa] found that the presence of
WMHs was related to subsequent cognitive decline, a higher risk of
developing dementia, stroke, and of mortality. Lesion volume at baseline
was also predictive of cognitive decline. Kloppenborg et al.
[@Kloppenborg:2014aa] of 23 cross-sectional studies reporting MRI and
concurrent neuropsychological results in patients with heterogeneous
diagnoses but without previously diagnosed cognitive impairment, found
that WMHs were associated with cognitive deficit (effect size of -0.10,
95% CI: -0.13 to -0.08) after controlling for age.


Despite the potential clinical significance of WMHs
these lesions receive little
attention in current clinical workflows. When reported in a standard
neuroradiologist interpretation, they are typically handled as
incidental findings and are assigned little clinical significance. This
likely reflects the impracticality of performing a detailed assessment
of number, volume, and distribution within a qualitative
neuroradiologist interpretation as well as the lack of correlative
information on how the presence and distribution of these lesions may
inform a diagnosis and prognosis in the appropriate clinical setting. To
date, automated or semi-automated tools for the detection of WMHs have
lacked the specificity and efficiency for the mining of large-scale
datasets to generate highly granular data on whether these lesions
possess any true diagnostic or prognostic value in the setting of a
specific disease process. The present communication describes a
supervised statistical learning tool that is appropriate for the
application to such large-scale datasets.

<!--

The currently described tool is just one example of how "supervised
learning" algorithms might be applied to aid in the diagnosis of TBI and
other disease processes through the specific identification of features
predictive of a given disease state. It is an important demonstration of
the potential power of these analytical approaches in the rapid but
comprehensive mining of information from neuroimaging examinations.
Supervised learning algorithms are presently employed across a wide
variety of settings for the rapid identification of predictive imaging
features [@Plis:2014aa;@Suk:2015aa;@Li:2014aa;@Liu:2015aa]. Automobile
manufacturers utilize these types of approaches to equip self-driving
vehicles to recognize and respond to unique external surroundings
through the identification of visual information sufficiently similar to
previously assimilated training data [@HadsellSBESKML09;@FarabetCNL12].
Similarly, in the context of the neuroimaging assessments, deep learning
approaches may allow for the rapid identification of information
predictive of disease state in an individual patient. These approaches
have been applied to the segmentation of macroscopically visible
structures [@Plis:2014aa;@Suk:2015aa;@Li:2014aa;@Liu:2015aa].
Additionally, these approaches might be applied to the interrogation of
imaging data in the individual patient with a primary quantitative
output metrics to include sequences such as diffusion tensor imaging
(DTI) and its variants, functional connectivity, perfusion weighted
imaging, and cortical thickness assessments. At present, these advanced
neuroimaging sequences are confined to cohort-based research studies due
to the lack of available analytical tools to assess the information in
the setting of the individual patient [@Mayer:2014aa]. Application of
deep learning approaches in the context of data with primary
quantitative outputs will require large scale normative and disease
specific databases. Building these large scale imaging libraries is
resource intensive and requires a multi-center approach with harmonized
scanners between sites and correlative non-imaging clinical data. Large
scale TBI data is becoming increasingly available through activities
such as the Chronic Effects of Neurotrauma Consortium (CENC),
Transforming Research and Clinical Knowledge in TBI (TRACK-TBI),
Collaborative European Neurotrauma Effectiveness Research in TBI
(CENTER-TBI), Department of Defense Alzheimerâ€™s Disease Neuroimaging
Initiative (DOD-ADNI), and other data being consolidated through FITBIR.
In concert with any available high quality normative neuroimaging data,
deep learning algorithms may be well positioned to help transform how
neuroimaging is interpreted for the clinical management of patients with
this disease process.

-->

\clearpage
