
## WMH segmentation

\begin{center}
\includegraphics[width=\textwidth]{./Figures/lesions.png}
\end{center}

<!-- 

* This is an update respecting current work.
* We published this work in March 2016.
* Have since gained access to the larger multi-site CENC data set.

-->

## Current pipeline

Stone et al. _Supervised learning technique for the automated identification of white 
matter hyperintensities in traumatic brain injury_, March, 2016.

\begin{center}
\includegraphics[width=\textwidth]{../Figures/wmhPipeline.png}
\end{center}

<!--

* This is the current pipeline.
* From training data (produced by James Stone), 
    * we generate feature images from the multi-modal training data (T1, T2, FLAIR),
    * we then build a 2-layer random forest model
    * A mean shape/intensity symmetric template is used for input
* To segment an individual subject
    * multi-modal image input
    * generate feature images
    * pass through RF model 

-->


## Features

\tiny
\begin{center}
\input{../featureImagesTable}
\end{center}
\normalsize

<!--

* For many machine learning algorithms, as in the case of 
  random forests, one of the most creative design aspects is
  determining which feature images one should use.
* This table is the list of feature images.
* It should be noted that these take an hour plus to generate.
  This time is for both training the random forest models
  and pushing each new subject through the finished pipeline.
* We will contrast these two characteristics 1) feature images 
  and 2) time as differences with future work.

-->

## Feature images

\begin{center}
$label \sim_{RF} feature_{1} + \ldots + feature_{n}$
\end{center}

<BR><BR>

\begin{center}
\includegraphics[width=\textwidth]{../Figures/featureImages.png}
\end{center}

<!--

* The functional dependence is illustrated by this equation:
    the label at each voxel (i.e., what tissue type) is dependent on the
    the weighted combination of all the features at that voxel.
* Below are axial examples of the set of feature images used to discriminate
  between the different tissue types.

-->

## Feature importance

\begin{center}
\includegraphics[width=0.6\textwidth]{../Figures/averageLeaveOneOut.png}
\end{center}

<!-- 

* The pipeline, as shown on slide 3, utilizes two concatenated random forest models
  where the output of the first is used as partial input to the second.
* When generating the RF models during training, we can get a sense of the
  "importance" of each of the features.

-->

## Sample results:  Site 1

\begin{center}
\includegraphics[width=0.75\textwidth]{../Figures/sampleResults.png}
\end{center}

<!-- 

* Here are sample results:
   * From Site 1 only 
   * Used a leave-one-out evaluation strategy.
       - take the ~25 subjects generated by James Stone
       - use 24 to create the RF models and then test on the remaining subject


-->

## Leave-one-out evaluation

\begin{center}
\includegraphics[width=\textwidth]{../Figures/evaluationResults.png}
\end{center}

<!--

* These are the evaluation measures showing improvement for the two "stages".
    * We used 
        - (a) sensitivity 
        - (b) positive predictive value
        - (c) F_1 score
        - (d) relative volume difference.
* Overall improvement in all three whole lesion-based measuers is seen as the second 
  Stage RF model is applied for all three quantile ranges. 
* The relative volume difference corresponding to the Stage 2 results tend to predict 
  a decreased predicted volume over the Stage 1 results.

-->

## Problems with current approach

* Takes a lot of time for new data
    1. Create initial set of feature images
    2. Run it through Stage 1 model
    3. Create more feature images
    4. Run subject through Stage 2 model
* We are using a relatively small training data set
* Modeling/training is limited to a single site
* Creative engineering is needed
    * Feature image selection
    * Are we choosing discriminative features?
* We have imbalanced data (e.g., way more GM than WMH voxels)
* No comparisons with clinical data (yet)

## What about deep learning?

* Exciting new possibilities with deep learning
* Potentially quicker for new data
    * Building initial model takes time __but__
    * no feature images are needed to create for new data.
* Optimization and architecture are used to learn the features
* Mature packages
    * TensorFlow, CNTK, Torch, Theano, Sci-TK, Caffe, mxnet, Keras
* Need lots of training data

## Current work 

1. Rebuild RF models from Site 1 balanced data $\leftarrow$
2. Employ all CENC data $\leftarrow$
3. Apply RF approach $\leftarrow$
4. Check clinical correlations
5. Manually refine data from 2.
6. Re-check clinical correlations
7. Use data from 5. to train deep learning model
8. Re-check clinical correlations

## Quick note on imbalanced data 

* 7 tissue voxel labels
    * CSF $(n = 208080, 18\%)$
    * gray matter $(n = 457437, 39\%)$
    * white matter $(n = 317788, 27\%)$
    * deep gray matter $(n = 33042, 2.8\%)$
    * brain stem $(n = 17975, 1.5\%)$
    * cerebellum $(n = 1369656, 12\%)$
    * WMH $(n = 901, 0.07\%)$
* SMOTe (Synthetic Minority Over-sampling Technique)
    * For "rare" events:  $\leq 15$\%
    * use bootstrapping and $k$-nearest neighbor


